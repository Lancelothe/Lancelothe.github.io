<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Java开发手册-泰山版来袭]]></title>
    <url>%2F2020%2F05%2F04%2FJava%E5%BC%80%E5%8F%91%E6%89%8B%E5%86%8C-%E6%B3%B0%E5%B1%B1%E7%89%88%E6%9D%A5%E8%A2%AD%2F</url>
    <content type="text"><![CDATA[会当凌绝顶，一览众山小 终于迎来了《Java开发手册》的一个新的版本——泰山版。 新版本说明此次泰山版发布，将带来三大亮点：新增5条日期时间规约；新增2条表别名sql规约；新增统一错误码规约。 5条日期时间规约 【强制】日期格式化时，传入pattern中表示年份统一使用小写的y。 说明：日期格式化时，yyyy表示当天所在的年，而大写的YYYY代表是week in which year（JDK7之后引入的概念），意思是当天所在的周属于的年份，一周从周日开始，周六结束，只要本周跨年，返回的YYYY就是下一年。 正例：表示日期和时间的格式如下所示： new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;) 【强制】在日期格式中分清楚大写的M和小写的m，大写的H和小写的h分别指代的意义。 说明：日期格式中的这两对字母表意如下： 1） 表示月份是大写的M； 2） 表示分钟则是小写的m； 3） 24小时制的是大写的H； 4） 12小时制的则是小写的h。 【强制】获取当前毫秒数：System.currentTimeMillis(); 而不是new Date().getTime()。 说明：如果想获取更加精确的纳秒级时间值，使用System.nanoTime的方式。在JDK8中，针对统计时间等场景，推荐使用Instant类。 【强制】不允许在程序任何地方中使用：1）java.sql.Date 2）java.sql.Time 3）java.sql.Timestamp。 说明：第1个不记录时间，getHours()抛出异常；第2个不记录日期，getYear()抛出异常；第3个在构造方法super((time/1000)*1000)，fastTime和nanos分开存储秒和纳秒信息。 反例： java.util.Date.after(Date)进行时间比较时，当入参是java.sql.Timestamp时，会触发JDK BUG(JDK9已修复)，可能导致比较时的意外结果。 【强制】不要在程序中写死一年为365天，避免在公历闰年时出现日期转换错误或程序逻辑错误。 正例： 12345// 获取今年的天数 int daysOfThisYear = LocalDate.now().lengthOfYear();// 获取指定某年的天数LocalDate.of(2011, 1, 1).lengthOfYear(); 反例： 123456// 第一种情况：在闰年366天时，出现数组越界异常 int[] dayArray = new int[365]; // 第二种情况：一年有效期的会员制，今年1月26日注册，硬编码365返回的却是1月25日 Calendar calendar = Calendar.getInstance(); calendar.set(2020, 1, 26); calendar.add(Calendar.DATE, 365); 【推荐】避免公历闰年2月问题。闰年的2月份有29天，一年后的那一天不可能是2月29日。 【推荐】使用枚举值来指代月份。如果使用数字，注意Date，Calendar等日期相关类的月份month取值在0-11之间。 说明：参考JDK原生注释，Month value is 0-based. e.g., 0 for January. 正例： Calendar.JANUARY，Calendar.FEBRUARY，Calendar.MARCH等来指代相应月份来进行传参或比较。 2条表别名sql规约 【强制】对于数据库中表记录的查询和变更，只要涉及多个表，都需要在列名前加表的别名（或表名）进行限定。 说明：对多表进行查询记录、更新记录、删除记录时，如果对操作列没有限定表的别名（或表名），并且操作列在多个表中存在时，就会抛异常。 正例：select t1.name from table_first as t1 , table_second as t2 where t1.id=t2.id; 反例：在某业务中，由于多表关联查询语句没有加表的别名（或表名）的限制，正常运行两年后，最近在某个表中增加一个同名字段，在预发布环境做数据库变更后，线上查询语句出现出1052异常：Column ‘name’ in field list is ambiguous。 【推荐】SQL语句中表的别名前加as，并且以t1、t2、t3、…的顺序依次命名。 说明：1）别名可以是表的简称，或者是根据表出现的顺序，以t1、t2、t3的方式命名。2）别名前加as使别名更容易识别。 正例：select t1.name from table_first as t1, table_second as t2 where t1.id=t2.id; 三目运算符规范 【强制】三目运算符condition? 表达式1 : 表达式2中，高度注意表达式1和2在类型对齐时，可能抛出因自动拆箱导致的NPE异常。 说明：以下两种场景会触发类型对齐的拆箱操作： 1） 表达式1或表达式2的值只要有一个是原始类型。 2） 表达式1或表达式2的值的类型不一致，会强制拆箱升级成表示范围更大的那个类型。 反例： 123456Integer a = 1; Integer b = 2; Integer c = null; Boolean flag = false; // a*b的结果是int类型，那么c会强制拆箱成int类型，抛出NPE异常 Integer result=(flag? a*b : c); 新增统一错误码规约统一错误码，就是统一度量衡，为你的应用与服务的稳定保驾护航，烦恼清空，快乐回家。泰山版新近出炉的错误码具有快速溯源、简单易记、沟通标准化三大优势。错误码为字符串类型，共 5 位，分成两个部分：错误产生来源和四位数字编号。 错误产生来源分为 A/B/C，以当前代码运行视角来进行判定。 A 表示错误来源于用户，比如请求参数错误，用户安装版本过低等问题； B 表示错误来源于当前系统，往往是业务逻辑出错，或程序健壮性差等问题； C 表示错误来源于第三方服务，比如 CDN 服务出错，消息投递超时等问题。 优秀的错误码可以迅速知道他们是怎么来滴，从哪儿来滴，来干啥滴。同时俺们的错误码具有三级结构，分为一级宏观错误码、二级宏观错误码、三级宏观错误码，这样的方案更加可扩展，有弹性，更多详细规则，见手册的附件的《错误码参考列表》。 作者QA作者孤尽也在QA视频中回答了新增的几条规约实际出现过的问题。 在对JDK源码阅读技巧上给我们提了3点： 1）一定要有发现美的眼睛； 2）一定要有主线思维； 3）不断打磨自己的基础，包括位运算、源码调试，甚至可以看看JVM的C++源码或者C++下的汇编代码。 你的Java开发规约在业界影响这么大，你之前想到过有这一天吗？ 作者表示没有想到有这么一天，从最初的的4、5个人的小团体走到阿里巴巴，最后发到业界去，他还是坚持初心，对大家有用有帮助，继续传播。 是什么支撑你每年推出新规约，我们知道这并不是你的本职工作。 作者表示在于两个词，热爱和卓越。但是要加上形容词。「奉献式的热爱」和「极致式的卓越」。 我们看到从去年的「华山版」开始，《Java开发手册》就不再有阿里巴巴这样的限定词，作者的本意也是希望来致敬全球的开发者。因为《Java开发手册》发展到今天，已经不是单单属于阿里巴巴或者孤尽个人，它属于整个业界大家整体智慧的一个结晶。希望大家一起努力，将代码演绎到极致，并写出更优雅的代码。 历史版本《Java开发手册》一直在迭代，不知道下一个版本是什么名字。 一起学习最后在阿里云开发者社区里，也特意给我们准备了7日训练营的打卡挑战，帮助大家更好的理解手册，小伙伴们一起来参加吧还有可能获得奖品。 相关资源地址GitHub（包含IntelliJ IDEA和Eclipse的插件）：alibaba/p3c: Alibaba Java Coding Guidelines 阿里云开发者社区：泰山版Java开发手册-阿里云开发者社区 求关注、分享、在看！！！ 你的支持是我创作最大的动力。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>开发手册</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ES遇到的问题]]></title>
    <url>%2F2019%2F04%2F04%2Fes-2019-04-04-ES%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[一、org.elasticsearch.action.NoShardAvailableActionException: No shard available for [get [event][event][SH601011_padt_20029340]: routing [null]]起因：2019-04-04 10:30（第二次）删除数据后插入数据发现未更新，查看服务日志发现出现下面报错：1232019-04-04 10:31:20.050|ERROR|c96bf1f26485aa05.c96bf1f26485aa05&lt;:c96bf1f26485aa05|c.x.s.s.c.s.e.EventServiceDisclosure|process symbol failed, symbol:SH601011org.elasticsearch.action.NoShardAvailableActionException: No shard available for [get [event][event][SH601011_padt_20029340]: routing [null]] at org.elasticsearch.action.support.single.shard.TransportSingleShardAction$AsyncSingleAction.perform(TransportSingleShardAction.java:209) 随后查看了ES集群的健康状态，发现状态变成红色，且活动分片只有98%多问了SRE同事，确认磁盘未满，且只有插入数据的那个索引状态为红色，但是三个 es节点的物理机 的磁盘空间都是 80%、90%、 79%顺便让SRE同事也清了下磁盘，保证后面的可用量。 这时发现健康状态持续恶化：unassigned_shards增多，同时还出现了initializing_shards 这时组内同事建议我重启ES集群，之后查看健康状态正常：无initializing_shards和unassigned_shards且活动分片数占比达到100%。 网络上相关问题解决方案：参考1-1：Reroute Unassigned Shards——遇到主shard 出现的解决方法就是重新路由 - bonelee - 博客园参考1-2：Elasticsearch几个问题的解决参考1-3：彻底解决 es 的 unassigned shards 症状 - 开发者头条 — 参考1-4的翻译版参考1-4：How to resolve unassigned shards in Elasticsearch | Datadog命令：curl -XPOST &quot;http://your.elasticsearch.host.com:9200/twitter/_flush/synced&quot;Step 1: Check Unassigned ShardsStep 2: Reroute# Step1 and Step2 结合的shell脚本，可快速转移UNASSIGNED分片12345678910111213for shard in $(curl -XGET http://localhost:9200/_cat/shards | grep UNASSIGNED | awk &apos;&#123;print $2&#125;&apos;); docurl -XPOST &apos;localhost:9200/_cluster/reroute&apos; -d &apos;&#123; &quot;commands&quot; : [ &#123; &quot;allocate&quot; : &#123; &quot;index&quot; : &quot;t37&quot;, # index name &quot;shard&quot; : $shard, &quot;node&quot; : &quot;datanode15&quot;, # node name &quot;allow_primary&quot; : true &#125;&#125;]&#125;&apos;sleep 5done 未分配分片的可能原因: Name Comment CLUSTER_RECOVERED Unassigned as a result of a full cluster recovery INDEX_REOPENED Unassigned as a result of opening a closed index DANGLING_INDEX_IMPORTED Unassigned as a result of importing a dangling index NEW_INDEX_RESTORED Unassigned as a result of restoring into a new index EXISTING_INDEX_RESTORED Unassigned as a result of restoring into a closed index REPLICA_ADDED Unassigned as a result of explicit addition of a replica ALLOCATION_FAILED Unassigned as a result of a failed allocation of the shard NODE_LEFT Unassigned as a result of the node hosting it leaving the cluster REROUTE_CANCELLED Unassigned as a result of explicit cancel reroute command REINITIALIZED When a shard moves from started back to initializing, for example, with shadow replicas REALLOCATED_REPLICA A better replica location is identified and causes the existing replica allocation to be cancelled 二、Unassigned Shards 无法reroute的问题1FileSystemException[/opt/elasticsearch/elasticsearch-node8/data/nodes/0/indices/FgLdgYTmTfazlP8i5K0Knw/0/index: Too many open files in system 参考2-1：解决elasticsearch集群Unassigned Shards 无法reroute的问题]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>ES</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ES集群相关]]></title>
    <url>%2F2019%2F03%2F04%2Fes-2019-03-04-ES%E9%9B%86%E7%BE%A4%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[elasticsearch-head启动cd elasticsearch-head grunt server 或者 输入npm run start启动 # 打开浏览器 http://localhost:9100 ES单机集群搭建修改完配置文件后，将压缩目录复制多份，然后修改对应配置文件的node.name、http.port、transport.tcp.port、discovery.zen.ping.unicast.hosts即可，node.master和node.data两个参数看需要修改，默认值都是true。 脚本一件启动1234./es-node-master/bin/elasticsearch -d./es-node-data-1/bin/elasticsearch -d./es-node-data-2/bin/elasticsearch -d./es-node-client/bin/elasticsearch -d elasticsearch启动 正常启动:${es目录}/bin/elasticsearch守护进程启动:${es目录}/bin/elasticsearch -d PS： http.port、transport.tcp.port、discovery.zen.ping.unicast.hosts也可以不设置，es会自动选取合适的端口来启动，默认使用多播方式通讯，这种方式在本地或者VPC环境下可以使用，但是不建议。 network.host这个参数和redis的host参数一样，根据填写的IP来限制访问权限，例如127.0.0.1那么就只有本地可以访问，192等内网IP那么就只有内网能访问，写公网IP的话外网才能访问。当我们在远程服务器上搭建服务时，如果设置的不是外网IP，很可能就是无法访问的。遇到这个问题我们可以通过使用netstat命令：netstat -tunlp | grep elasticsearch来查看ip与端口的绑定使用情况来检查。 参考：elasticsearch本地集群搭建及远程服务器搭建注意事项 - wkNote - CSDN博客 启用X-pack（ELK Stack 6.3以后版本默认自带x-pack，不用手动安装） 运行elasticsearch 启用trial license（30天试用，后面有破解方法） curl -H “Content-Type:application/json” -XPOST http://127.0.0.1:9200/_xpack/license/start_trial?acknowledge=true 设置用户名密码 命令：bin/elasticsearch-setup-passwords interactive elasticsearch.yml中开启安全验证配置 添加配置： xpack.security.enabled: true 参考：elasticsearch6.3.1 启用x-pack - 11111 - CSDN博客elasticsearch6.3.2之x-pack6.3.2破解安装并配合kibana使用 - qq_25475209的博客 - CSDN博客 破解参考：elasticsearch6.3.2之x-pack6.3.2破解安装并配合kibana使用 - 我的广场 Kibana相关配置12345678910111213141516171819202122# 配置elasticsearch.yaml# 是否开启安全验证xpack.security.enabled: true# 是否开启监控xpack.monitoring.enabled: true# 是否开启图形xpack.graph.enabled: true# 是否开启watcher 仅仅es配置xpack.watcher.enabled: true# 配置kibana.ymlserver.port: 5601server.name: &quot;my-kibana&quot;elasticsearch.url: &quot;http://127.0.0.1:9200&quot;# 这里配用户名、密码elasticsearch.username: elasticelasticsearch.password: XXXXXXXXXXX# 为了防止启动报警告，所以增加一个随机的32位encryptionKeyxpack.reporting.encryptionKey: 7d2e5883e72b7b0077305966442f51e3xpack.security.encryptionKey: 7d2e5883e72b7b0077305966442f51e4# 是否开启报表仅仅kibana配置xpack.reporting.enabled: true 监控台Monitoring刚开始用Kibana账号登陆进去没有数据，说没有开启，但是点击Turn on后又报错，捣鼓了半天，最后用ElasticSearch账号密码进入监控台才有数据！后来第二天再试，用Kibana账号也有数据了，这里还不太清楚原因，或许是哪里配置的生效关系 Kibana启动1234567-H 参数解释 设置kibana 网络正常启动: ./kibana -H 0.0.0.0守护进程启动:本次守护进程启动,主要用到了 nohup命令:在 kibana目录内运行!! (与kibana bin文件夹同级) nohup ./bin/kibana -H 0.0.0.0 &gt; ./log/kibana.log 2&gt;&amp;1 &amp; PS： 关于集群多节点配置x-pack。每个节点都需要安装x-pack。但是kibana只需要安装一次。 x-pack的密码修改。(需要指定content-type) curl -H “Content-Type: application/json” -XPUT -u elastic -p ‘内网ip:9303/_xpack/security/user/elastic/_password’ -d ‘{ “password” : “密码”}’ 如果忘记elastic用户的密码，可以再创建一个用户超级角色的用户（用户admin，密码admin1） bin/x-pack/users useradd admin -p admin1 -r superuser 上面的请求改一下: curl -H “Content-Type: application/json” -XPUT -u admin -p ‘内网ip:9303/_xpack/security/user/elastic/_password’ -d ‘{ “password” : “密码”}’ ES集群节点配置下面用到只是一些主要配置，还有更多的请看链接详解。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778# 这个参数必须设置 此参数是用来允许单机允许多个实例，默认不允许node.max_local_storage_nodes: 32# 集群名称，同一个集群里的此参数要一致cluster.name: my-es# 节点名称，同一集群的节点之间需要不一致node.name: node-2#node.attr.rack: r1# 设置候选主节点，默认 truenode.master: true# 设置数据节点，默认 truenode.data: true# 设置预处理节点，默认 truenode.ingest: true# 设置默认索引分片个数，默认为5片。#index.number_of_shards: 5# 设置默认索引副本个数，默认为1个副本。如果采用默认设置，而你集群只配置了一台机器，那么集群的健康度为yellow，也就是所有的数据都是可用的，但是某些复制没有被分配（健康度可用 curl &apos;localhost:9200/_cat/health?v&apos; 查看， 分为绿色、黄色或红色。绿色代表一切正常，集群功能齐全，&gt;黄色意味着所有的数据都是可用的，但是某些复制没有被分配，红色则代表因为某些原因，某些数据不可用）#index.number_of_replicas: 1# 数据目录路径path.data: /Users/lancelot/Documents/lancelot/service/elasticsearch-cluster/es-node2/data# 日志目录路径path.logs: /Users/lancelot/Documents/lancelot/service/elasticsearch-cluster/es-node2/logs# 设置为true来锁住内存不进行swapping。因为当jvm开始swapping时es的效率 会降低，# 所以要保证它不swap，可以把ES_MIN_MEM和ES_MAX_MEM两个环境变量设置成同一个值，# 并且保证机器有足够的内存分配给es。 同时也要允许elasticsearch的进程可以锁住内存，# linux下启动es之前可以通过`ulimit -l unlimited`命令设置。#bootstrap.memory_lock: true# 设置绑定的ip地址，可以是ipv4或ipv6的，默认为0.0.0.0，绑定这台机器的任何一个ip。#network.bind_host: 127.0.0.1# 设置其它节点和该节点交互的ip地址，如果不设置它会自动判断，值必须是个真实的ip地址。(可以不配)#network.publish_host: 127.0.0.1# 此节点对外的ip 本地直接写127.0.0.1即可(这个参数是用来同时设置bind_host和publish_host上面两个参数)network.host: 127.0.0.1# 对外暴露的http访问端口http.port: 9202# 内部节点间通讯TCP端口，单播使用transport.tcp.port: 9302# 设置是否压缩tcp传输时的数据，默认为false，不压缩。#transport.tcp.compress: true# 是否使用http协议对外提供服务，默认为true，开启。#http.enabled: false# 组播设置，默认true#discovery.zen.ping.multicast.enabled: false# 单播访问的地址 域名直接改成127.0.0.1即可 或者修改下本机host将127.0.0.1映射到多个域名，比如1个client 3个master 所以配了4个地址discovery.zen.ping.unicast.hosts: [&quot;127.0.0.1:9301&quot;, &quot;127.0.0.1:9302&quot;,&quot;127.0.0.1:9303&quot;]# 设置master选举需要赞同的最小节点数# 值得计算方式为 master候选节点数除2加1# 例如 node.master值为true的节点数量为5 值即为（5/2)+1 = 3discovery.zen.minimum_master_nodes: 2# 设置集群中自动发现其它节点时ping连接超时时间，默认为3秒，对于比较差的网络环境可以高点的值来防止自动发现时出错。#discovery.zen.ping.timeout: 3s# 设置集群中N个节点启动时进行数据恢复，默认为1。#gateway.recover_after_nodes: 3# 设置初始化数据恢复进程的超时时间，默认是5分钟。#gateway.recover_after_time: 5m# 设置这个集群中节点的数量，默认为2，一旦这N个节点启动，就会立即进行数据恢复。#gateway.expected_nodes: 2# 初始化数据恢复时，并发恢复线程的个数，默认为4。#cluster.routing.allocation.node_initial_primaries_recoveries: 4# 添加删除节点或负载均衡时并发恢复线程的个数，默认为4。#cluster.routing.allocation.node_concurrent_recoveries: 2#action.destructive_requires_name: true# CORS跨域访问设置，使head插件可以访问eshttp.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot;# 集群中其他节点# 修改对应配置文件的node.name、http.port、transport.tcp.port、discovery.zen.ping.unicast.hosts即可，node.master和node.data两个参数看需要修改，默认值都是true。 一. 获取License网站：https://register.elastic.co/二. 查看License命令：curl -XGET -u elastic:changem ‘http://10.10.55.1:9200/_xpack/license&#39;三. 更新License第一步注册完毕后，会收到一封邮件，内容会包含下载地址，下载完毕后运行命令： curl -XPUT -u elastic:changeme ‘http://10.10.55.1:9200/_xpack/license&#39; -H “Content-Type: application/json” -d @license.json license文件下载：license_2018.json {“license”:{“uid”:”bee39742-cc50-4e83-9e49-17366d9a109c”,”type”:”basic”,”issue_date_in_millis”:1515628800000,”expiry_date_in_millis”:1547251199999,”max_nodes”:100,”issued_to”:”shan yl (XueQiu)”,”issuer”:”Web Form”,”signature”:”AAAAAwAAAA2PkBbsGKLXXURLaOugAAABmC9ZN0hjZDBGYnVyRXpCOW5Bb3FjZDAxOWpSbTVoMVZwUzRxVk1PSmkxaktJRVl5MUYvUWh3bHZVUTllbXNPbzBUemtnbWpBbmlWRmRZb25KNFlBR2x0TXc2K2p1Y1VtMG1UQU9TRGZVSGRwaEJGUjE3bXd3LzRqZ05iLzRteWFNekdxRGpIYlFwYkJiNUs0U1hTVlJKNVlXekMrSlVUdFIvV0FNeWdOYnlESDc3MWhlY3hSQmdKSjJ2ZTcvYlBFOHhPQlV3ZHdDQ0tHcG5uOElCaDJ4K1hob29xSG85N0kvTWV3THhlQk9NL01VMFRjNDZpZEVXeUtUMXIyMlIveFpJUkk2WUdveEZaME9XWitGUi9WNTZVQW1FMG1DenhZU0ZmeXlZakVEMjZFT2NvOWxpZGlqVmlHNC8rWVVUYzMwRGVySHpIdURzKzFiRDl4TmM1TUp2VTBOUlJZUlAyV0ZVL2kvVk10L0NsbXNFYVZwT3NSU082dFNNa2prQ0ZsclZ4NTltbU1CVE5lR09Bck93V2J1Y3c9PQAAAQCe8MNM2+qs5TKCC/soPeHSdYMxkdQt+uYGfqjFGowb5meW7xSTvmsxp8IQc5iOdwtFJqZq9cJakCz1PSmsDxasUCLVnWJ59qZA4RzqWoC4qUqY94W41Vocz3oZNpCUTU4tVi0yd24n8Q1w1dp1wv6Ujm2/OJ5vkuj2iIQk6csnr8Q2kPUyDcGb+xPK74NTEj6XEsB7D8yEA8ftPeCEff1QgsV9LPPvzCIaWLmyrL30P/CS95twG6hr/DAaGK2oPP9UIsE5U+9Q3b4Ly6urSJVbv0rLaPB4nrt4/JERRSqytgvhg5rX+zs1P0eQRLMPlBL/6Q7NwmQYb8NZWHrCI/du”,”start_date_in_millis”:1515628800000}}]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>ES</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在同一台电脑上使用两个Git账号]]></title>
    <url>%2F2019%2F02%2F19%2Fgit-2019-02-19-%E5%9C%A8%E5%90%8C%E4%B8%80%E5%8F%B0%E7%94%B5%E8%84%91%E4%B8%8A%E4%BD%BF%E7%94%A8%E4%B8%A4%E4%B8%AAGit%E8%B4%A6%E5%8F%B7%2F</url>
    <content type="text"><![CDATA[说明由于公司团队使用 GitLab 来托管代码，同时，个人在 Github 上还有一些代码仓库，可公司邮箱与个人邮箱是不同的，由此产生的 SSH key 也是不同的，这就造成了冲突 ，文章提供此类问题的解决方案：如何在一台机器上面同时使用 Github 与 Gitlab 的服务？ 问题产生场景 无密码与远程服务器交互的秘密 - SSH如果采用ssh 协议或者git 协议通过终端命令对远程仓库进行push操作的时候，大概的过程如下：（前提在 Github 上已经配置的本机的 SSH Public Key） 客户端发起一个 Public Key 的认证请求，并发送RSA Key的模数作为标识符。（关于 RSA Key 详细 维基百科)） 服务端检查是否存在请求帐号的公钥（Linux中存储在~/.ssh/authorized_keys文件中），以及其拥有的访问权限。 服务端使用对应的公钥对一个随机的256位的字符串进行加密，并发送给客户端。 客户端使用私钥对字符串进行解密，并将其结合session id生成一个MD5值发送给服务端。 结合session id的目的是为了避免攻击者采用重放攻击（replay attack）。 服务端采用同样的方式生成MD5值与客户端返回的MD5值进行比较，完成对客户端的认证。 将push的内容进行加密与服务端传输数据。 关于 SSH，请查看 SSH原理简介 ，更通俗易懂的文章请查看阮一峰-SSH原理与运用（一）：远程登录 。 具体场景无论使用哪种代码托管服务商，对于 Git 而言，邮箱 是识别用户的唯一手段，所以对于不同的服务商，由于邮箱不同，那么通过邮件名创建的 SSH Key 自然是不同的，这时候在不同的服务商之间进行 push 命令的时候，Git 是不知道使用哪个 SSH Key ，自然导致 push 的失败。场景如下： 在公司团队使用搭建的 Gitlab 服务，提交邮箱`xirong.liu@corp.xx.com， 个人 Github 服务，提交邮箱ixirong.liu@gmail.com` （Bitbucket 同理）。 有两个Github账户，不同的账户提交不同的仓库内容。 解决方案方案一：同一个邮箱由于邮箱是识别的唯一手段，那么自然的，这两者采用同一个邮箱，生成的 public key 也会是同一个，上传到 Github 或者 Gitlab 上面，在 Git 的配置中 ，设置好 Global 的配置 ：git config --global user.name &#39;xirong.liu&#39; &amp;&amp; git config --global user.email &#39;xirong.liu@corp.xx.com&#39; 进行日常的开发是没有问题的。 实际生活中采用同一个邮箱的可能性并不是太大，这就引出了方案二 方案二：基于config文件所谓的方案二，原理上就是对 SSH 协议配置 config 文件，对不同的域名采用不同的认证密钥。 git config 介绍 Git有一个工具被称为git config，它允许你获得和设置配置变量；这些变量可以控制Git的外观和操作的各个方面。这些变量可以被存储在三个不同的位置： /etc/gitconfig 文件：包含了适用于系统所有用户和所有库的值。如果你传递参数选项’--system’ 给 git config，它将明确的读和写这个文件。 ~/.gitconfig 文件 ：具体到你的用户。你可以通过传递 ‘--global’ 选项使Git 读或写这个特定的文件。 位于 Git 目录的 config 文件 (也就是 .git/config) ：无论你当前在用的库是什么，特定指向该单一的库。每个级别重写前一个级别的值。因此，在 .git/config 中的值覆盖了在/etc/gitconfig中的同一个值，可以通过传递‘--local’选项使Git 读或写这个特定的文件。 由于采用了不同的邮箱，对不同的服务商进行提交，所以此时我们经常配置的 git config --global 就不能常用了，必须在每个仓库的目录下进行配置自己的用户名、邮箱。（嫌麻烦？xirong 是这么解决的，由于个人的 Github 上有较多的仓库，而自己团队的代码基本上都是稳定的，有数的几个，所以在 git config --global user.email &#39;ixirong.liu@gmail.com&#39; 中全局配置的是个人邮箱，在团队的项目中配置） 1. 配置 Git 用户名、邮箱如刚才所说，xirong 的配置如下： 12345678# 全局配置，Github仓库中默认使用此配置git config --global user.name 'xirong' &amp;&amp; git config --global user.email 'ixirong.liu@gmail.com'# 团队项目配置，每次新创建一个项目，需要执行下git config --local user.name 'xirong.liu' &amp;&amp; git config --local user.email 'xirong.liu@corp.xxx.com'# 比如，我就是git config --local user.name 'lancelothe' &amp;&amp; git config --local user.email '294044124@qq.com' 2. 生成 ssh key 上传到 Github/Gitlabssh key 默认生成后保存在 ~/.ssh/目录下 ，默认为 id_rsa 和 id_rsa.pub 两个文件，由于我们需要分开配置，所以这么做： 12345# 生成公钥、密钥的同时指定文件名，Gitlab使用ssh-keygen -t rsa -f ~/.ssh/id_rsa.gitlab -C "xirong.liu@corp.xxx.com"# 生成默认，Github使用ssh-keygen -t rsa -C "ixirong.liu@gmail.com" 命令执行完成后，这时~/.ssh目录下会多出id_rsa.gitlab和id_rsa.gitlab.pub两个文件，id_rsa.gitlab.pub 里保存的就是我们要使用的key，这个key就是用来上传到 Gitlab上的。 3. 配置 config 文件在 ~/.ssh目录下，如果不存在，则新建 touch ~/.ssh/config文件 ，文件内容添加如下： 12345678910Host *.corp.xxx.com IdentityFile ~/.ssh/id_rsa.gitlab User xirong.liu# my ~/.ssh/configHost github.com HostName github.com IdentityFile ~/.ssh/id_rsa.github User lancelothe 配置完成后，符合 *.corp.xxx.com后缀的 Git 仓库，均采取~/.ssh/id_rsa.gitlab 密钥进行验证，其它的采取默认的。 4. 上传public key 到 Github/Gitlab以Github为例，过程如下： 登录github 点击右上方的Accounting settings图标 选择 SSH key 点击 Add SSH key 在出现的界面中填写SSH key的名称，填一个你自己喜欢的名称即可，然后将上面拷贝的~/.ssh/id_rsa.pub文件内容粘帖到key一栏，在点击“add key”按钮就可以了。 添加过程github会提示你输入一次你的github密码 ，确认后即添加完毕。 上传Gitlab的过程一样，请自己操作。 5. 验证是否OK由于每个托管商的仓库都有唯一的后缀，比如 Github的是 `git@github.com:*`，所以可以这样测试： 1234➜ ~ ssh -T git@github.comHi xirong! You've successfully authenticated, but GitHub does not provide shell access.➜ ~ ssh -T git@gitlab.devWelcome to GitLab, xirong.liu! 看到这些 Welcome 信息，说明就是 OK的了。 以后，如果还有任何的需求，都可以这么解决，看下 xirong 的几个托管仓库： 12345678910➜ ~ ll ~/.sshtotal 40-rw-r--r-- 1 xirong staff 264 Jul 10 14:42 config-rw------- 1 xirong staff 3243 Jul 10 14:09 id_rsa-rw------- 1 xirong staff 1675 Jan 28 20:39 id_rsa.gitlab-rw-r--r-- 1 xirong staff 407 Jan 28 20:39 id_rsa.gitlab.pub-rw-r--r-- 1 xirong staff 747 Jul 10 14:09 id_rsa.pub-rw------- 1 xirong staff 1679 Jun 22 11:42 id_rsa_gitcafe-rw-r--r-- 1 xirong staff 407 Jun 22 11:42 id_rsa_gitcafe.pub-rw-r--r-- 1 xirong staff 9139 Jul 29 15:08 known_hosts]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git 骚操作]]></title>
    <url>%2F2019%2F01%2F30%2Fgit-2019-01-30-Git-%E9%AA%9A%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[删除git库中untracked files（未监控）的文件 - RonnyJiang的博客 - CSDN博客Git Stash 用法 命令行快捷键设置 vim ~/.bashrc12345678910111213141516alias gs=&apos;git status &apos;alias gl=&apos;git log &apos;alias ga=&apos;git add &apos;alias gpu=&apos;git pull upstream&apos;alias gpo=&apos;git pull origin&apos;alias gp=&apos;git push &apos;alias gb=&apos;git branch &apos;alias gcm=&apos;git commit&apos;alias gd=&apos;git diff&apos;alias gc=&apos;git checkout &apos;alias gau=&apos;git remote add upstream&apos;alias gr=&apos;git remote -v&apos;alias gsa=&apos;git stash&apos;alias gsp=&apos;git stash pop&apos;alias ss=&apos;ssh jump&apos; source ~/.bashrc加载配置文件]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java8新特性（五）之 Date Time API]]></title>
    <url>%2F2019%2F01%2F16%2Fjava-2019-01-16-Java8%E6%96%B0%E7%89%B9%E6%80%A7%EF%BC%88%E4%BA%94%EF%BC%89%E4%B9%8B-Date-Time-API%2F</url>
    <content type="text"><![CDATA[Java8新增的就是LocalDate、LocalTime、LocalDateTime、Instant、Duration、Period几个大类。 之前用joda能做到的，现在用Java8里面的api几乎都能做到，语法也很相似。 LocalDateTime的一些用法123456789101112131415161718192021// 取时间戳long localDateTime = LocalDateTime.of(LocalDate.now().minusDays(1), LocalTime.MIN).toInstant(ZoneOffset.UTC).toEpochMilli();// 获取当天零点时间LocalDateTime today_start = LocalDateTime.of(LocalDate.now(), LocalTime.MIN);//当天零点String td_st_str =today_start.format(DateTimeFormatter.ofPattern(&quot;yyyyMMddHHmmss&quot;));// 获取当天结束时间LocalDateTime today_end = LocalDateTime.of(LocalDate.now(), LocalTime.MAX);//当天零点// 设置2018年1月1日LocalDateTime.of(2018, 1, 1, 0, 0).toLocalDate();// 获取2018年1月1日时间戳LocalDateTime.of(2018, 1, 1, 0, 0).toInstant(ZoneOffset.of(&quot;+8&quot;)).toEpochMilli();// 此时减一年时间戳1LocalDateTime.of(LocalDate.now().minusYears(1), LocalTime.MIN).toInstant(ZoneOffset.of(&quot;+8&quot;)).toEpochMilli();// 此时减一年时间戳2long lastYear = LocalDateTime.now().minusYears(1).withHour(0).withMinute(0).withSecond(0).withNano(0).toInstant(ZoneOffset.of(&quot;+8&quot;)).toEpochMilli(); LocalDate、LocalDateTime与timestamp、Date的转换 - 简书 Date和LocalDate互转Date对象表示特定的日期和时间，而LocalDate(Java8)对象只包含没有任何时间信息的日期。因此，如果我们只关心日期而不是时间信息，则可以在Date和LocalDate之间进行转换。 Date转LocalDate12345678Date date = new Date();Instant instant = date.toInstant();ZoneId zoneId = ZoneId.systemDefault();// atZone()方法返回在指定时区从此Instant生成的ZonedDateTime。LocalDate localDate = instant.atZone(zoneId).toLocalDate();System.out.println(&quot;Date = &quot; + date);System.out.println(&quot;LocalDate = &quot; + localDate); LocalDate转Date12345678ZoneId zoneId = ZoneId.systemDefault();LocalDate localDate = LocalDate.now();ZonedDateTime zdt = localDate.atStartOfDay(zoneId);Date date = Date.from(zdt.toInstant());System.out.println(&quot;LocalDate = &quot; + localDate);System.out.println(&quot;Date = &quot; + date); LocalDate和String互转LocalDate转String12LocalDate localDate = LocalDate.now();String dateStr = localDate.format(DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd&quot;)); LocalDateTime转String123456789101112131415161718192021LocalDateTime dateTime = LocalDateTime.now();//使用预定义实例来转换DateTimeFormatter fmt = DateTimeFormatter.ISO_LOCAL_DATE;String dateStr = dateTime.format(fmt);System.out.println(&quot;LocalDateTime转String[预定义]:&quot;+dateStr);//使用pattern来转换//12小时制与24小时制输出由hh的大小写决定DateTimeFormatter fmt12 = DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd hh:mm:ss:SSS&quot;);String dateStr12 = dateTime.format(fmt12);System.out.println(&quot;LocalDateTime转String[pattern](12小时制):&quot;+dateStr12);DateTimeFormatter fmt24 = DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd HH:mm:ss:SSS&quot;);String dateStr24 = dateTime.format(fmt24);System.out.println(&quot;LocalDateTime转String[pattern](24小时制):&quot;+dateStr24);//如果想要给12小时制时间加上am/pm,这样子做：fmt12 = DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd hh:mm:ss:SSS a&quot;);dateStr12 = dateTime.format(fmt12);System.out.println(&quot;LocalDateTime转String[pattern](12小时制带am/pm):&quot;+dateStr12); String转LocalDate和LocalDateTime123456String str = &quot;2017-11-21 14:41:06:612&quot;;DateTimeFormatter fmt = DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd HH:mm:ss:SSS&quot;);LocalDate date = LocalDate.parse(str, fmt);LocalDateTime time = LocalDateTime.parse(str, fmt);System.out.println(&quot;date:&quot;+date);System.out.println(&quot;time:&quot;+time); 时区Java 8中的时区操作被很大程度上简化了，新的时区类java.time.ZoneId是原有的java.util.TimeZone类的替代品。ZoneId对象可以通过ZoneId.of()方法创建，也可以通过ZoneId.systemDefault()获取系统默认时区： 12ZoneId shanghaiZoneId = ZoneId.of("Asia/Shanghai");ZoneId systemZoneId = ZoneId.systemDefault(); of()方法接收一个“区域/城市”的字符串作为参数，你可以通过getAvailableZoneIds()方法获取所有合法的“区域/城市”字符串： 1Set&lt;String&gt; zoneIds = ZoneId.getAvailableZoneIds(); 对于老的时区类TimeZone，Java 8也提供了转化方法： 1ZoneId oldToNewZoneId = TimeZone.getDefault().toZoneId(); 有了ZoneId，我们就可以将一个LocalDate、LocalTime或LocalDateTime对象转化为ZonedDateTime对象： 12LocalDateTime localDateTime = LocalDateTime.now();ZonedDateTime zonedDateTime = ZonedDateTime.of(localDateTime, shanghaiZoneId); 将zonedDateTime打印到控制台为： 12017-01-05T15:26:56.147+08:00[Asia/Shanghai] ZonedDateTime对象由两部分构成，LocalDateTime和ZoneId，其中2017-01-05T15:26:56.147部分为LocalDateTime，+08:00[Asia/Shanghai]部分为ZoneId。 另一种表示时区的方式是使用ZoneOffset，它是以当前时间和世界标准时间（UTC）/格林威治时间（GMT）的偏差来计算，例如： 123ZoneOffset zoneOffset = ZoneOffset.of("+09:00");LocalDateTime localDateTime = LocalDateTime.now();OffsetDateTime offsetDateTime = OffsetDateTime.of(localDateTime, zoneOffset); DateTimeFormatter详解DateTimeFormatter我们更多的是直接使用pattern来做转换，其实这个类本身已经提供了一些预定义好的实例供我们使用。下面把两者的具体释义和示例都贴出来供大家参考。 预定义123456789101112131415161718192021Predefined Formatters Formatter Description Example---------------------- ---------------------- ------------ofLocalizedDate(dateStyle) Formatter with date style from the locale &apos;2011-12-03&apos;ofLocalizedTime(timeStyle) Formatter with time style from the locale &apos;10:15:30&apos;ofLocalizedDateTime(dateTimeStyle) Formatter with a style for date and time from the locale &apos;3 Jun 2008 11:05:30&apos;ofLocalizedDateTime(dateStyle,timeStyle) Formatter with date and time styles from the locale &apos;3 Jun 2008 11:05&apos;BASIC_ISO_DATE Basic ISO date &apos;20111203&apos;ISO_LOCAL_DATE ISO Local Date &apos;2011-12-03&apos;ISO_OFFSET_DATE ISO Date with offset &apos;2011-12-03+01:00&apos;ISO_DATE ISO Date with or without offset &apos;2011-12-03+01:00&apos;; &apos;2011-12-03&apos;ISO_LOCAL_TIME Time without offset &apos;10:15:30&apos;ISO_OFFSET_TIME Time with offset &apos;10:15:30+01:00&apos;ISO_TIME Time with or without offset &apos;10:15:30+01:00&apos;; &apos;10:15:30&apos;ISO_LOCAL_DATE_TIME ISO Local Date and Time &apos;2011-12-03T10:15:30&apos;ISO_OFFSET_DATE_TIME Date Time with Offset &apos;2011-12-03T10:15:30+01:00&apos;ISO_ZONED_DATE_TIME Zoned Date Time &apos;2011-12-03T10:15:30+01:00[Europe/Paris]&apos;ISO_DATE_TIME Date and time with ZoneId &apos;2011-12-03T10:15:30+01:00[Europe/Paris]&apos;ISO_ORDINAL_DATE Year and day of year &apos;2012-337&apos;ISO_WEEK_DATE Year and Week &apos;2012-W48-6&apos;ISO_INSTANT Date and Time of an Instant &apos;2011-12-03T10:15:30Z&apos;RFC_1123_DATE_TIME RFC 1123 / RFC 822 &apos;Tue, 3 Jun 2008 11:05:30 GMT&apos; Pattern123456789101112131415161718192021222324252627282930313233343536373839404142434445464748All letters &apos;A&apos; to &apos;Z&apos; and &apos;a&apos; to &apos;z&apos; are reserved as pattern letters. The following pattern letters are defined: Symbol Meaning Presentation Examples ------ ------- ------------ ------- G era text AD; Anno Domini; A u year year 2004; 04 y year-of-era year 2004; 04 D day-of-year number 189 M/L month-of-year number/text 7; 07; Jul; July; J d day-of-month number 10 Q/q quarter-of-year number/text 3; 03; Q3; 3rd quarter Y week-based-year year 1996; 96 w week-of-week-based-year number 27 W week-of-month number 4 E day-of-week text Tue; Tuesday; T e/c localized day-of-week number/text 2; 02; Tue; Tuesday; T F week-of-month number 3 a am-pm-of-day text PM h clock-hour-of-am-pm (1-12) number 12 K hour-of-am-pm (0-11) number 0 k clock-hour-of-am-pm (1-24) number 0 H hour-of-day (0-23) number 0 m minute-of-hour number 30 s second-of-minute number 55 S fraction-of-second fraction 978 A milli-of-day number 1234 n nano-of-second number 987654321 N nano-of-day number 1234000000 V time-zone ID zone-id America/Los_Angeles; Z; -08:30 z time-zone name zone-name Pacific Standard Time; PST O localized zone-offset offset-O GMT+8; GMT+08:00; UTC-08:00; X zone-offset &apos;Z&apos; for zero offset-X Z; -08; -0830; -08:30; -083015; -08:30:15; x zone-offset offset-x +0000; -08; -0830; -08:30; -083015; -08:30:15; Z zone-offset offset-Z +0000; -0800; -08:00; p pad next pad modifier 1 &apos; escape for text delimiter &apos;&apos; single quote literal &apos; [ optional section start ] optional section end # reserved for future use &#123; reserved for future use &#125; reserved for future use]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java8</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java8新特性（四）之 Optional 类]]></title>
    <url>%2F2019%2F01%2F15%2Fjava-2019-01-15-Java8%E6%96%B0%E7%89%B9%E6%80%A7%EF%BC%88%E5%9B%9B%EF%BC%89%E4%B9%8B-Optional-%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[本篇文章将详细介绍Optional类，以及如何用它消除代码中的null检查。Optional是为了防止NullPointerException，使代码更优雅。 避免使用null检查作为Java开发人员，几乎所有人都遇到过NullPointerException异常，大多数人遇到NullPointerException异常时都会在异常出现的地方加上if代码块来判断值不为空，比如下面的代码： 123456789101112public void bindUserToRole(User user) &#123; if (user != null) &#123; String roleId = user.getRoleId(); if (roleId != null) &#123; Role role = roleDao.findOne(roleId); if (role != null) &#123; role.setUserId(user.getUserId()); roleDao.save(role); &#125; &#125; &#125;&#125; 这是比较普遍的做法，为了避免出现NullPointerException异常，手动对可能为null值进行了处理，不过代码看起来非常糟糕，业务逻辑被淹没在if逻辑判断中，也许下面的代码看起来可读性稍好一些： 12345678910111213141516public String bindUserToRole(User user) &#123; if (user == null) &#123; return; &#125; String roleId = user.getRoleId(); if (roleId == null) &#123; return; &#125; Role = roleDao.findOne(roleId); if (role != null) &#123; role.setUserId(user.getUserId()); roleDao.save(role); &#125;&#125; 上面的代码避免了深层的if语句嵌套，但本质上是一样的，方法内有三个不同的返回点，出错后调试也不容易，因为你不知道是那个值导致了NullPointerException异常。 基于上面的原因，Java 8中引入了一个新的类Optional，用以避免使用null值引发的种种问题。 Optional类java.util.Optional&lt;T&gt;类是一个封装了Optional值的容器对象，Optional值可以为null，如果值存在，调用isPresent()方法返回true，调用get()方法可以获取值。 创建Optional对象Optional类提供类三个方法用于实例化一个Optional对象，它们分别为empty()、of()、ofNullable()，这三个方法都是静态方法，可以直接调用。 empty()方法用于创建一个没有值的Optional对象： 1Optional&lt;String&gt; emptyOpt = Optional.empty(); empty()方法创建的对象没有值，如果对emptyOpt变量调用isPresent()方法会返回false，调用get()方法抛出NullPointerException异常。 of()方法使用一个非空的值创建Optional对象： 12String str = "Hello World";Optional&lt;String&gt; notNullOpt = Optional.of(str); ofNullable()方法接收一个可以为null的值： 1Optional&lt;String&gt; nullableOpt = Optional.ofNullable(str); 如果str的值为null，得到的nullableOpt是一个没有值的Optional对象。 提取Optional对象中的值如果我们要获取User对象中的roleId属性值，常见的方式是直接获取： 1234String roleId = null;if (user != null) &#123; roleId = user.getRoleId();&#125; 使用Optional中提供的map()方法可以以更简单的方式实现： 12Optional&lt;User&gt; userOpt = Optional.ofNullable(user);Optional&lt;String&gt; roleIdOpt = userOpt.map(User::getRoleId); 使用orElse()方法获取值Optional类还包含其他方法用于获取值，这些方法分别为： orElse()：如果有值就返回，否则返回一个给定的值作为默认值； orElseGet()：与orElse()方法作用类似，区别在于生成默认值的方式不同。该方法接受一个Supplier&lt;? extends T&gt;函数式接口参数，用于生成默认值； orElseThrow()：与前面介绍的get()方法类似，当值为null时调用这两个方法都会抛出NullPointerException异常，区别在于该方法可以指定抛出的异常类型。 下面来看看这三个方法的具体用法： 123456String str = "Hello World";Optional&lt;String&gt; strOpt = Optional.of(str);String orElseResult = strOpt.orElse("Hello Shanghai");String orElseGet = strOpt.orElseGet(() -&gt; "Hello Shanghai");String orElseThrow = strOpt.orElseThrow( () -&gt; new IllegalArgumentException("Argument 'str' cannot be null or blank.")); 此外，Optional类还提供了一个ifPresent()方法，该方法接收一个Consumer&lt;? super T&gt;函数式接口，一般用于将信息打印到控制台： 12Optional&lt;String&gt; strOpt = Optional.of("Hello World");strOpt.ifPresent(System.out::println); 使用filter()方法过滤filter()方法可用于判断Optional对象是否满足给定条件，一般用于条件过滤： 12Optional&lt;String&gt; optional = Optional.of("lw900925@163.com");optional = optional.filter(str -&gt; str.contains("164")); 在上面的代码中，如果filter()方法中的Lambda表达式成立，filter()方法会返回当前Optional对象值，否则，返回一个值为空的Optional对象。 如何正确使用Optional通过上面的例子可以看出，Optional类可以优雅的避免NullPointerException带来的各种问题，不过，你是否真正掌握了Optional的用法？假设你试图使用Optional来避免可能出现的NullPointerException异常，编写了如下代码： 1234567Optional&lt;User&gt; userOpt = Optional.ofNullable(user);if (userOpt.isPresent()) &#123; User user = userOpt.get(); // do something...&#125; else &#123; // do something...&#125; 坦白说，上面的代码与我们之前的使用if语句判断空值没有任何区别，没有起到Optional的正真作用： 12345if (user != null) &#123; // do something...&#125; else &#123; // do something...&#125; 当我们从之前版本切换到Java 8的时候，不应该还按照之前的思维方式处理null值，Java 8提倡函数式编程，新增的许多API都可以用函数式编程表示，Optional类也是其中之一。这里有几条关于Optional使用的建议： 尽量避免在程序中直接调用Optional对象的get()和isPresent()方法； 避免使用Optional类型声明实体类的属性； 第一条建议中直接调用get()方法是很危险的做法，如果Optional的值为空，那么毫无疑问会抛出NullPointerException异常，而为了调用get()方法而使用isPresent()方法作为空值检查，这种做法与传统的用if语句块做空值检查没有任何区别。 第二条建议避免使用Optional作为实体类的属性，它在设计的时候就没有考虑过用来作为类的属性，如果你查看Optional的源代码，你会发现它没有实现java.io.Serializable接口，这在某些情况下是很重要的（比如你的项目中使用了某些序列化框架），使用了Optional作为实体类的属性，意味着他们不能被序列化。 下面我们通过一些例子讲解Optional的正确用法： 正确创建Optional对象上面提到创建Optional对象有三个方法，empty()方法比较简单，没什么特别要说明的。主要是of()和ofNullable()方法。当你很确定一个对象不可能为null的时候，应该使用of()方法，否则，尽可能使用ofNullable()方法，比如： 12345678public static void method(Role role) &#123; // 当Optional的值通过常量获得或者通过关键字new初始化，可以直接使用of()方法 Optional&lt;String&gt; strOpt = Optional.of("Hello World"); Optional&lt;User&gt; userOpt = Optional.of(new User()); // 方法参数中role值不确定是否为null，使用ofNullable()方法创建 Optional&lt;Role&gt; roleOpt = Optional.ofNullable(role);&#125; orElse()方法的使用1return str != null ? str : "Hello World" 上面的代码表示判断字符串str是否为空，不为空就返回，否则，返回一个常量。使用Optional类可以表示为： 1return strOpt.orElse("Hello World") 简化if-else1234567891011User user = ...if (user != null) &#123; String userName = user.getUserName(); if (userName != null) &#123; return userName.toUpperCase(); &#125; else &#123; return null; &#125;&#125; else &#123; return null;&#125; 上面的代码可以简化成： 123456User user = ...Optional&lt;User&gt; userOpt = Optional.ofNullable(user);return userOpt.map(User::getUserName) .map(String::toUpperCase) .orElse(null); 总结一下，新的Optional类让我们可以以函数式编程的方式处理null值，抛弃了Java 8之前需要嵌套大量if-else代码块，使代码可读性有了很大的提高。 坑使用OPtional的orElse()问题 - liubingyu12345的博客 - CSDN博客]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java8</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java8新特性（三） 之 Stream API]]></title>
    <url>%2F2018%2F12%2F25%2Fjava-2018-12-25-Java8%E6%96%B0%E7%89%B9%E6%80%A7%EF%BC%88%E4%B8%89%EF%BC%89-%E4%B9%8B-Stream-API%2F</url>
    <content type="text"><![CDATA[Stream API本文继续介绍Java 8的另一个新特性——Stream API。Stream API是对Java中集合操作的增强，可以利用它进行各种过滤、排序、分组、聚合等操作。Stream API配合Lambda表达式可以加大的提高代码可读性和编码效率，Stream API也支持并行操作，我们不用再花费很多精力来编写容易出错的多线程代码了，Stream API已经替我们做好了，并且充分利用多核CPU的优势。借助Stream API和Lambda，开发人员可以很容易的编写出高性能的并发处理程序。 简介Stream API是Java 8中加入的一套新的API，主要用于处理集合操作，不过它的处理方式与传统的方式不同，称为“数据流处理”。流（Stream）类似于关系数据库的查询操作，是一种声明式操作。比如要从数据库中获取所有年龄大于20岁的用户的名称，并按照用户的创建时间进行排序，用一条SQL语句就可以搞定，不过使用Java程序实现就会显得有些繁琐，这时候可以使用流： 123456List&lt;String&gt; userNames = users.stream() .filter(user -&gt; user.getAge() &gt; 20) .sorted(comparing(User::getCreationDate)) .map(User::getUserName) .collect(toList()); 在这个大数据的时代，数据变得越来越多样化，很多时候我们会面对海量数据，并对其做一些复杂的操作（比如统计，分组），依照传统的遍历方式（for-each），每次只能处理集合中的一个元素，并且是按顺序处理，这种方法是极其低效的。你也许会想到并行处理，但是编写多线程代码并非易事，很容易出错并且维护困难。不过在Java 8之后，你可以使用Stream API来解决这一问题。 Stream API将迭代操作封装到了内部，它会自动的选择最优的迭代方式，并且使用并行方式处理时，将集合分成多段，每一段分别使用不同的线程处理，最后将处理结果合并输出。 需要注意的是，流只能遍历一次，遍历结束后，这个流就被关闭掉了。如果要重新遍历，可以从数据源（集合）中重新获取一个流。如果你对一个流遍历两次，就会抛出java.lang.IllegalStateException异常：1234List&lt;String&gt; list = Arrays.asList("A", "B", "C", "D");Stream&lt;String&gt; stream = list.stream();stream.forEach(System.out::println);stream.forEach(System.out::println); // 这里会抛出java.lang.IllegalStateException异常，因为流已经被关闭 流通常由三部分构成： 数据源：数据源一般用于流的获取，比如本文开头那个过滤用户的例子中users.stream()方法。 中间处理：中间处理包括对流中元素的一系列处理，如：过滤（filter()），映射（map()），排序（sorted()）。 终端处理：终端处理会生成结果，结果可以是任何不是流值，如List；也可以不返回结果，如stream.forEach(System.out::println)就是将结果打印到控制台中，并没有返回。Stream中的操作可以分为两大类：中间操作与结束操作，中间操作只是对操作进行了记录，只有结束操作才会触发实际的计算（即惰性求值），这也是Stream在迭代大集合时高效的原因之一。中间操作又可以分为无状态（Stateless）操作与有状态（Stateful）操作，前者是指元素的处理不受之前元素的影响；后者是指该操作只有拿到所有元素之后才能继续下去。结束操作又可以分为短路与非短路操作，这个应该很好理解，前者是指遇到某些符合条件的元素就可以得到最终结果；而后者是指必须处理所有元素才能得到最终结果。 中间操作也称为惰性操作。终端操作也称为急切操作。惰性操作不处理元素，直到在流上调用热切操作。流上的中间操作产生另一流。Streams链接操作以创建流管道。 创建流创建流的方式有很多，具体可以划分为以下几种： 由值创建流使用静态方法Stream.of()创建流，该方法接收一个变长参数：1Stream&lt;Stream&gt; stream = Stream.of("A", "B", "C", "D"); 也可以使用静态方法Stream.empty()创建一个空的流：1Stream&lt;Stream&gt; stream = Stream.empty(); 由数组创建流使用静态方法Arrays.stream()从数组创建一个流，该方法接收一个数组参数：12String[] strs = &#123;"A", "B", "C", "D"&#125;;Stream&lt;Stream&gt; stream = Arrays.stream(strs); 通过文件生成流使用java.nio.file.Files类中的很多静态方法都可以获取流，比如Files.lines()方法，该方法接收一个java.nio.file.Path对象，返回一个由文件行构成的字符串流：1Stream&lt;String&gt; stream = Files.lines(Paths.get("text.txt"), Charset.defaultCharset()); 通过函数创建流java.util.stream.Stream中有两个静态方法用于从函数生成流，他们分别是Stream&lt;T&gt; generate(Supplier&lt;T&gt; s)和Stream&lt;T&gt; iterate(final T seed, final UnaryOperator&lt;T&gt; f)：1234// iteartorStream.iterate(0, n -&gt; n + 2).limit(51).forEach(System.out::println);// generateStream.generate(() -&gt; "Hello Man!").limit(10).forEach(System.out::println); 第一个方法会打印100以内的所有偶数，第二个方法打印10个Hello Man!。值得注意的是，这两个方法生成的流都是无限流，没有固定大小，可以无穷的计算下去，在上面的代码中我们使用了limit()来避免打印无穷个值。 一般来说，iterate()用于生成一系列值，比如生成以当前时间开始之后的10天的日期：1Stream.iterate(LocalDate.now(), date -&gt; date.plusDays(1)).limit(10).forEach(System.out::println); generate()方法用于生成一些随机数，比如生成10个UUID：1Stream.generate(() -&gt; UUID.randomUUID().toString()).limit(10).forEach(System.out::println); 使用流Stream接口中包含许多对流操作的方法，这些方法分别为： filter()：对流的元素过滤 map()：将流的元素映射成另一个类型 distinct()：去除流中重复的元素 sorted()：对流的元素排序 forEach()：对流中的每个元素执行某个操作 peek()：与forEach()方法效果类似，不同的是，该方法会返回一个新的流，而forEach()无返回 limit()：截取流中前面几个元素 skip()：跳过流中前面几个元素 toArray()：将流转换为数组 reduce()：对流中的元素归约操作，将每个元素合起来形成一个新的值 collect()：对流的汇总操作，比如输出成List集合 anyMatch()：匹配流中的元素，类似的操作还有allMatch()和noneMatch()方法 findFirst()：查找第一个元素，类似的还有findAny()方法 max()：求最大值 min()：求最小值 count()：求总数 下面逐一介绍这些方法的用法。 简单栗子：1234567Stream.of(1, 8, 5, 2, 1, 0, 9, 2, 0, 4, 8) .filter(n -&gt; n &gt; 2) // 对元素过滤，保留大于2的元素 .distinct() // 去重，类似于SQL语句中的DISTINCT .skip(1) // 跳过前面1个元素 .limit(2) // 返回开头2个元素，类似于SQL语句中的SELECT TOP .sorted() // 对结果排序 .forEach(System.out::println); 过滤1List&lt;Apple&gt; filterList = appleList.stream().filter(a -&gt; a.getName().equals("香蕉")).collect(Collectors.toList()); 求和(规约)12345//计算 总金额// map -&gt; reduceBigDecimal totalMoney = appleList.stream().map(Apple::getMoney).reduce(BigDecimal.ZERO, BigDecimal::add);//计算 数量int sum = appleList.stream().mapToInt(Apple::getNum).sum(); 提取Bean某一属性1234// 取Bean某一属性stuList.stream() .map(Student::getId).distinct() .collect(Collectors.toList()); 去重 一般去重1List&lt;Integer&gt; distinctNumbers = numbers.stream().distinct().collect(Collectors.toList()); 条件去重12345678910111213141516171819202122// 根据Bean的某种属性去重// 首先定义一个过滤器public static &lt;T&gt; Predicate&lt;T&gt; distinctByKey(Function&lt;? super T, Object&gt; keyExtractor) &#123; Map&lt;Object, Boolean&gt; seen = new ConcurrentHashMap&lt;&gt;(); return object -&gt; seen.putIfAbsent(keyExtractor.apply(object), Boolean.TRUE) == null;&#125;List&lt;User&gt; distinctUsers = users.stream() .filter(distinctByKey(User::getName)) .collect(Collectors.toList());这种去重也可以对多个Key进行，将多个Key拼接成一个Key。private String getGroupingByKey(Person p)&#123; return p.getAge()+"-"+p.getName();&#125;下面的分组也是用了这个思想。// 或者List&lt;HKCsm&gt; unique = list.stream() .collect(Collectors .collectingAndThen(Collectors .toCollection(() -&gt; new TreeSet&lt;&gt;(Comparator.comparing(o -&gt; o.getIDVUNIC()))), ArrayList::new)); 排序排序需重新赋值，内部操作循环的foreach的话就不用赋值新变量list = list.stream().sorted(byNumber).collect(Collectors.toList()); 多属性先后顺序排序：自己重写comparator方法12345678910111213141516171819@Testpublic void testSort_with_multipleComparator() throws Exception &#123; ArrayList&lt;Human&gt; humans = Lists.newArrayList( new Human(&quot;tomy&quot;, 22), new Human(&quot;li&quot;, 25) ); Comparator&lt;Human&gt; comparator = (h1, h2) -&gt; &#123; if (h1.getName().equals(h2.getName())) &#123; return Integer.compare(h1.getAge(), h2.getAge()); &#125; return h1.getName().compareTo(h2.getName()); &#125;; humans.sort(comparator.reversed()); Assert.assertThat(&quot;tomy&quot;, equalTo(humans.get(0).getName()));&#125; 12345678910111213141516171819202122// 一般排序// 定义一个比较器，用于排序Comparator&lt;Rule&gt; byNumber = Comparator.comparingInt(Rule::getNumber);// 获取排序后的list，先通过filter筛选，然后在排序List&lt;Rule&gt; rule = lstRule.stream().filter(s -&gt; s.getCode() == 2).sorted(byNumber).collect(Collectors.toList());// 联合排序Comparator&lt;Rule&gt; byNumber = Comparator.comparingInt(Rule::getNumber);Comparator&lt;Rule&gt; byCode = Comparator.comparingInt(Rule::getCode);Comparator&lt;Rule&gt; byNumberAndCode = byNumber.thenComparing(byCode);// byNumberAndCode是一个联合排序的比较器List&lt;Rule&gt; rule = lstRule.stream().filter(s -&gt; s.getCode() == 2).sorted(byNumberAndCode).collect(Collectors.toList());// 排序时包括nullList&lt;User&gt; nList = list.stream() .sorted(Comparator.comparing(User::getCode, Comparator.nullsFirst(String::compareTo))) .collect(Collectors.toList());List&lt;User&gt; list = minPriceList.stream() .sorted(Comparator.comparing(l -&gt; l.getCreateDate(), Comparator.nullsLast(Date::compareTo))) .collect(Collectors.toList()); 更多参考：Java8：Lambda表达式增强版Comparator和排序 - ImportNew 分组此方法类似Mysql的group by，但是可能比sql的复杂语句来得简单些。 辅助POJO static class Person { private String name; private int age; private long salary; Person(String name, int age, long salary) { this.name = name; this.age = age; this.salary = salary; } @Override public String toString() { return String.format(&quot;Person{name=&apos;%s&apos;, age=%d, salary=%d}&quot;, name, age, salary); } } 针对单个属性分组12345678// 一般分组后的结构是Map，key是分组的属性，value是组成员Map&lt;Integer, List&lt;Person&gt;&gt; peopleByAge = people.stream().collect(Collectors.groupingBy(Person::getAge));Map&lt;Integer, List&lt;Person&gt;&gt; peopleByAge = people.stream().collect(Collectors.groupingBy(Person::getAge, Collectors.toList()));Map&lt;Integer, List&lt;Person&gt;&gt; peopleByAge = people.stream().collect(Collectors.groupingBy(p -&gt; p.age, Collectors.mapping((Person p) -&gt; p, toList())));上面三种方法返回均相同，分组后的Map里的value也可以根据Collectors.groupingBy方法的第二个参数设置不同，Collectors里还有更多的方法，如求和、最值、均值、拼接。 针对多个属性分组12345678910111213141516171819202122232425262728293031323334353637383940414243方式一：Map&lt;String, Map&lt;Integer, List&lt;Person&gt;&gt;&gt; map = people.stream() .collect(Collectors.groupingBy(Person::getName, Collectors.groupingBy(Person::getAge));map.get(&quot;Fred&quot;).get(18);方式二：定义一个表示分组的类：//静态内部类class Person &#123; public static class NameAge &#123; public NameAge(String name, int age) &#123; ... &#125; // 注意 重写方法 must implement equals and hash function &#125; public NameAge getNameAge() &#123; return new NameAge(name, age); &#125;&#125;Map&lt;NameAge, List&lt;Person&gt;&gt; map = people.collect(Collectors.groupingBy(Person::getNameAge));map.get(new NameAge(&quot;Fred&quot;, 18));不定义分组类也可以使用如apache commons pair如果您使用这些库之一。Map&lt;Pair&lt;String, Integer&gt;, List&lt;Person&gt;&gt; map = people.collect(Collectors.groupingBy(p -&gt; Pair.of(p.getName(), p.getAge())));map.get(Pair.of(&quot;Fred&quot;, 18));最终方式：将多个字段拼接成一个新字段，在使用Java8的groupBy进行分组。上面的去重里我也是沿用了这个思想。这个方法虽然看起来简单笨拙，但是却是最有效的解决了我的问题的，多个字段如果大于2个字段，上面的Pair就不是很好用，并且分组出来的结构也复杂。Map&lt;String, List&lt;Person&gt;&gt; peopleBySomeKey = people .collect(Collectors.groupingBy(p -&gt; getGroupingByKey(p), Collectors.mapping((Person p) -&gt; p, toList())));//write getGroupingByKey() functionprivate String getGroupingByKey(Person p)&#123; return p.getAge()+&quot;-&quot;+p.getName();&#125; 分组求和123//分组求和，key是分组属性名Map&lt;String, Long&gt; tt = orgHoldingDatas.stream() .collect(Collectors.groupingBy(OrgHoldingData::getOrgTypeCode, Collectors.summingLong(OrgHoldingData::getHeldNum))); 分组相加1234567891011121314151617181920212223list.stream() .sorted(Comparator.comparing(HKCsm::getPSNREFC)) .collect(Collectors.groupingBy(HKCsm::getIDVUNIC)) .forEach((k, v) -&gt; &#123; Optional&lt;HKCsm&gt; csm = v.stream().reduce((v1, v2) -&gt; &#123; v1.setPSNNAME_OGDIS(v1.getPSNNAME_OGDIS() + "、" + v2.getPSNNAME_OGDIS()); list.remove(v2); return v1; &#125;); &#125;);// 或者holderList.stream().collect(Collectors.groupingBy(HkMjshhshgStu::getShhnameOgdis)) .forEach((k, v) -&gt; &#123; Optional&lt;HkMjshhshgStu&gt; sum = v.stream().reduce((v1, v2) -&gt; &#123; //合并 v1.setNumrts(v1.getNumrts() + v2.getNumrts()); v1.setPctishg(v1.getPctishg() + v2.getPctishg()); return v1; &#125;); if (sum.isPresent()) &#123; items.add(sum.get()); &#125; &#125;); 自定义分组123456789101112Map&lt;String, List&lt;OrgHoldingData&gt;&gt; tt = orgHoldingDatas.stream() .collect(Collectors.groupingBy((Function&lt;OrgHoldingData, String&gt;) org -&gt; &#123; String key; if (org.getOrgTypeEncode().equals("1")) &#123; key = "苹果"; &#125; else if (org.getOrgTypeEncode().equals("2")) &#123; key = "香蕉"; &#125; else &#123; key = "其他"; &#125; return key; &#125;, Collectors.toList())); 分区分区的话就结果就只有两个部分part这种。要么是这一个区要么是另一个。12Map&lt;Boolean, List&lt;Student&gt;&gt; map4 = students.stream() .collect(Collectors.partitioningBy(student -&gt; student.getScore() &gt; 90)); 巧用flatMap123// 应该使用flatMap . flatMap()的作用在于打平List&lt;String&gt; reList = list.stream().map(item -&gt; item.split(" ")).flatMap(Arrays::stream).distinct() .collect(Collectors.toList()); 规约规约是什么？规约就是我们想要处理后要进行计算的东西，如上面我们进行的 求和、分组、分区、 流统计 DoubleSummaryStatistics LongSummaryStatistics IntSummaryStatistics并行流并行流使用集合的parallelStream()方法可以获取一个并行流。Java内部会将流的内容分割成若干个子部分，然后将它们交给多个线程并行处理，这样就将工作的负担交给多核CPU的其他内核处理。 在并行流中，我们关注最多的大概就是性能问题。在观察发现，在选择合适的数据结构和处理后，并行流确实可以优于平时的for循环。 坑 在Stream.of创建的流中，对于流的使用只能操作一次，操作后会有个标志位被置为true，如果再次对此流进行操作，会报错。但是对于集合的流形式，如list.stream()不会有问题，可多次操作。 parallelStream 的多线程并发写list会发生线程安全问题，list数据少了，导致数组越界。建议使用线程安全的集合类。深入浅出parallelStream - 梦铃之境的专栏 - CSDN博客记一次java8 parallelStream使用不当引发的血案 - AbeJeffrey的个人空间 - 开源中国java8的ParallelStream踩坑记录-云栖社区-阿里云 性能测试Java Stream API性能测试 - CarpenterLee - 博客园 参考Java8 新特性之流式数据处理 - 深蓝至尊 - 博客园Java 8新特性（二）：Stream API | 一书生VOID的博客]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java8</tag>
        <tag>Lambda</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java8新特性（二） 之 函数式接口]]></title>
    <url>%2F2018%2F12%2F18%2Fjava-2018-12-18-Java8%E6%96%B0%E7%89%B9%E6%80%A7%EF%BC%88%E4%BA%8C%EF%BC%89-%E4%B9%8B-%E5%87%BD%E6%95%B0%E5%BC%8F%E6%8E%A5%E5%8F%A3%2F</url>
    <content type="text"><![CDATA[函数式接口如果你的好奇心使你翻看Runnable接口源代码，你会发现该接口被一个@FunctionalInterface的注解修饰，这是Java 8中添加的新注解，用于表示 函数式接口。 函数式接口又是什么鬼？在Java 8中，把那些仅有一个抽象方法的接口称为函数式接口。如果一个接口被@FunctionalInterface注解标注，表示这个接口被设计成函数式接口，只能有一个抽象方法，如果你添加多个抽象方法，编译时会提示“Multiple non-overriding abstract methods found in interface XXX”之类的错误。 标注为FunctionalInterface的接口被称为函数式接口，该接口只能有一个自定义方法，但是可以包括从object类继承而来的方法。如果一个接口只有一个方法，则编译器会认为这就是一个函数式接口。是否是一个函数式接口，需要注意的有以下几点： 该注解只能标记在”有且仅有一个抽象方法”的接口上。 JDK8接口中的静态方法和默认方法，都不算是抽象方法。 接口默认继承java.lang.Object，所以如果接口显示声明覆盖了Object中方法，那么也不算抽象方法。 该注解不是必须的，如果一个接口符合”函数式接口”定义，那么加不加该注解都没有影响。加上该注解能够更好地让编译器进行检查。如果编写的不是函数式接口，但是加上了@FunctionInterface，那么编译器会报错。 在一个接口中定义两个自定义的方法，就会产生Invalid ‘@FunctionalInterface’ annotation; FunctionalInterfaceTest is not a functional interface错误. 函数式方法又能做什么？Java8允许你以Lambda表达式的方式为函数式接口提供实现，通俗的说，你可以将整个Lambda表达式作为接口的实现类。 除了Runnable之外，Java 8中内置了许多函数式接口供开发者使用，这些接口位于java.util.function包中。如： name type result desc Consumer Consumer T -&gt; void 接收T对象，不返回值 Predicate Predicate T -&gt; boolean 接收T对象并返回boolean Function Function&lt;T, R&gt; T -&gt; R 接收T对象，返回R对象 Supplier Supplier void -&gt; T 提供T对象（例如工厂），不接收值 UnaryOperator UnaryOperator T -&gt; T 接收T对象，返回T对象 BinaryOperator BinaryOperator T,T -&gt; T 接收两个T对象，返回T对象 如果输入参数是基本类型，为了避免自动拆箱装箱，可以使用其他基本类型的函数接口。 Functioninterface Function&lt;T, R&gt; 接口包含一个apply方法、两个默认方法（compose、andThen）和一个静态方法identity。apply是接口的基本方法。compose、andThen是一对儿方法，他们的区别在于执行的顺序不同。 12345//返回一个先执行before函数对象apply方法再执行当前函数对象apply方法的函数对象default &lt;V&gt; Function&lt;V, R&gt; compose(Function&lt;? super V, ? extends T&gt; before) &#123; Objects.requireNonNull(before); return (V v) -&gt; apply(before.apply(v));&#125; 12345//返回一个先执行当前函数对象apply方法再执行after函数对象apply方法的函数对象。default &lt;V&gt; Function&lt;T, V&gt; andThen(Function&lt;? super R, ? extends V&gt; after) &#123; Objects.requireNonNull(after); return (T t) -&gt; after.apply(apply(t));&#125; 1234567// 根据上面的解释想一下执行结果Function&lt;Integer, Integer&gt; name = e -&gt; e * 2;Function&lt;Integer, Integer&gt; square = e -&gt; e * e;int value = name.andThen(square).apply(3);int value2 = name.compose(square).apply(3);//返回一个执行了apply()方法之后只会返回输入参数的函数对象Object identity = Function.identity().apply("Test"); Consumerinterface Consumer&lt;T&gt;接口包含一个void accept(T t);方法、默认方法andThen.1234default Consumer&lt;T&gt; andThen(Consumer&lt;? super T&gt; after) &#123; Objects.requireNonNull(after); return (T t) -&gt; &#123; accept(t); after.accept(t); &#125;;&#125; 只有一个默认方法也是和它的返回类型有关系，因为返回的是void。 Predicateinterface Predicate&lt;T&gt;接口包含一个boolean test(T t);方法，三个默认方法（and，negate,or），还有一个静态方法。我们也知道Predicate接口是返回boolean类型的，所以一看就知道是条件判断的。举几个栗子吧：1234567891011String name = "hello";Predicate&lt;String&gt; predicate = x -&gt; x.equals("hello");Predicate&lt;String&gt; predicate2 = x -&gt; x.length() &lt; 2;// and 多个Predicate条件并的关系判断，第一个为false就不往下走了，满足短路原则System.out.println(predicate.and(predicate2).test(name));// or 多个Predicate条件或的关系判断，同样满足短路原则System.out.println(predicate.or(predicate2).test(name));// negate 取反的意思，就是否的条件判断System.out.println(predicate.and(predicate2.negate()).test(name));// isEqual 静态方法，判断是否相等System.out.println(Predicate.isEqual(name).test(name)); SupplierSupplier只有一个get()方法。我们来看看几个栗子：12345678910Supplier&lt;String&gt; supplier = () -&gt; "hello world";//get方法不接受参数，返回一个结果System.out.println("supplier = [" + supplier.get() + "]");//替代不接受参数的工厂方法Supplier&lt;Student&gt; studentSupplier = () -&gt; new Student();System.out.println(studentSupplier.get());//因为Student的构造方法不接受参数，返回一个结果，符合Supplier接口的要求，可以简写如下：Supplier&lt;Student&gt; studentSupplier2 = Student::new; 总结函数式接口其实差别不大，只是参数和返回的不同，只要想明白其中的一种，其他的也就懂了。 参考JDK8新特性-java.util.function-Function接口 Java8的一些新特性 java.util.function包 Java JVM（七）：Function，Consumer，Predicate 接口]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java8</tag>
        <tag>Lambda</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java8新特性（一） 之 Lambda表达式]]></title>
    <url>%2F2018%2F12%2F15%2Fjava-2018-12-15-Java8%E6%96%B0%E7%89%B9%E6%80%A7%EF%BC%88%E4%B8%80%EF%BC%89-%E4%B9%8B-Lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[Lambda表达式是什么Lambda表达式（lambda expression）是一个匿名函数，由数学中的λ演算而得名。在Java 8中可以把Lambda表达式理解为匿名函数，它没有名称，但是有参数列表、函数主体、返回类型等。 Lambda表达式的语法如下： (parameters) -&gt; { statements; } 为什么要使用Lambda表达式？前面你也看到了，在Java中使用内部类显得十分冗长，要编写很多样板代码，Lambda表达式正是为了简化这些步骤出现的，它使代码变得清晰易懂。 如何使用Lambda表达式Lambda表达式是为了简化内部类的，你可以把它当成是内部类的一种简写方式，只要是有内部类的代码块，都可以转化成Lambda表达式： 1234567891011// Comparator排序List&lt;Integer&gt; list = Arrays.asList(3, 1, 4, 5, 2);list.sort(new Comparator&lt;Integer&gt;() &#123; @Override public int compare(Integer o1, Integer o2) &#123; return o1.compareTo(o2); &#125;&#125;);// 使用Lambda表达式简化list.sort((o1, o2) -&gt; o1.compareTo(o2)); 12345678910// Runnable代码块Thread thread = new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println("Hello Man!"); &#125;&#125;);// 使用Lambda表达式简化Thread thread = new Thread(() -&gt; System.out.println("Hello Man!")); 可以看出，只要是内部类的代码块，就可以使用Lambda表达式简化，并且简化后的代码清晰易懂。 方法引用甚至，Comparator排序的Lambda表达式还可以进一步简化： list.sort(Integer::compareTo); 这种写法被称为 方法引用，方法引用是Lambda表达式的简便写法。如果你的Lambda表达式只是调用这个方法，最好使用名称调用，而不是描述如何调用，这样可以提高代码的可读性。 方法引用使用::分隔符，分隔符的前半部分表示引用类型，后面半部分表示引用的方法名称。例如：Integer::compareTo表示引用类型为Integer，引用名称为compareTo的方法。 对于 Lambda 表达式到方法引用的简化，我们提供以下规则： Lambda 表达式 方法引用 (args) -&gt; ClassName.staticMethod(args) ClassName::staticMethod (arg0, …) -&gt; arg0.instanceMethod(…) ClassName::instanceMethod (args) -&gt; expression.instanceMethod(args) expression::instanceMethod 特别的，对于构造函数的方法引用： ClassName::new类似使用方法引用的例子还有打印集合中的元素到控制台中：list.forEach(System.out::println);]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java8</tag>
        <tag>Lambda</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IntelliJ IDEA使用]]></title>
    <url>%2F2018%2F11%2F30%2FIntelliJ-IDEA%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[好用的插件 lokbok项目中经常使用bean，entity等类，绝大部分数据类类中都需要get、set、toString、equals和hashCode方法，虽然eclipse和idea开发环境下都有自动生成的快捷方式，但自动生成这些代码后，如果bean中的属性一旦有修改、删除或增加时，需要重新生成或删除get/set等方法，给代码维护增加负担。而使用了lombok则不一样，使用了lombok的注解(@Setter,@Getter,@ToString,@@RequiredArgsConstructor,@EqualsAndHashCode或@Data)之后，就不需要编写或生成get/set等方法，很大程度上减少了代码量，而且减少了代码维护的负担。故强烈建议项目中使用lombok，去掉bean中get、set、toString、equals和hashCode等方法的代码。 IDEA安装插件lombok 添加lombok的maven的pom.xml依赖： 12345&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.10&lt;/version&gt;&lt;/dependency&gt; 添加注解 12345678910111213141516171819202122package com.lombok.demo;import lombok.EqualsAndHashCode;import lombok.Getter;import lombok.Setter;import lombok.ToString;/** * Created by zhangzh on 2017/2/8. */@Setter@Getter@ToString@EqualsAndHashCodepublic class Student &#123; private String name; private int age; private String male; private String studentNo;&#125; 更多注解等你发现，比如：@Data, @Log 参数优化Mac 下的地址 vim /Applications/IntelliJ\ IDEA.app/Contents/bin/idea.vmoptions1234567891011121314151617-Xms128m-Xmx750m-XX:ReservedCodeCacheSize=240m-XX:+UseCompressedOops-Dfile.encoding=UTF-8-XX:+UseConcMarkSweepGC-XX:SoftRefLRUPolicyMSPerMB=50-ea-Dsun.io.useCanonCaches=false-Djava.net.preferIPv4Stack=true-Djdk.http.auth.tunneling.disabledSchemes=&quot;&quot;-XX:+HeapDumpOnOutOfMemoryError-XX:-OmitStackTraceInFastThrow-Xverify:none-XX:ErrorFile=$USER_HOME/java_error_in_idea_%p.log-XX:HeapDumpPath=$USER_HOME/java_error_in_idea.hprof 更新下面文件后重启，不会太卡了12345678910111213141516-Xms2200m-Xmx2200m-XX:ReservedCodeCacheSize=680m-XX:+UseCompressedOops-Dfile.encoding=UTF-8-XX:+UseConcMarkSweepGC-XX:SoftRefLRUPolicyMSPerMB=50-ea-Dsun.io.useCanonCaches=false-Djava.net.preferIPv4Stack=true-XX:+HeapDumpOnOutOfMemoryError-XX:-OmitStackTraceInFastThrow-Xverify:none-XX:ErrorFile=$USER_HOME/java_error_in_idea_%p.log-XX:HeapDumpPath=$USER_HOME/java_error_in_idea.hprof-Xbootclasspath/a:../lib/boot.jar 或者12345678910111213141516171819202122232425262728-Xms4400m-Xmx4400m-Xmn1000m-XX:PermSize=768m-XX:MaxPermSize=768m-Xss512K-XX:ReservedCodeCacheSize=128m-XX:SurvivorRatio=1-XX:+UseParNewGC-XX:+UseConcMarkSweepGC-XX:+UseCMSCompactAtFullCollection-XX:+UseCMSInitiatingOccupancyOnly-XX:CMSInitiatingOccupancyFraction=70-XX:+CMSParallelRemarkEnabled-XX:+CMSClassUnloadingEnabled-XX:CMSFullGCsBeforeCompaction=0-XX:LargePageSizeInBytes=200M-Dsun.io.useCanonCaches=false-Djava.net.preferIPv4Stack=true-Dsun.rmi.dgc.client.gcInterval=10800000-Dsun.rmi.dgc.server.gcInterval=10800000-XX:SoftRefLRUPolicyMSPerMB=0-XX:+DisableExplicitGC-XX:+PrintClassHistogram-XX:+PrintGCDetails-XX:+PrintGCTimeStamp-XX:+PrintHeapAtGC-Xloggc:gc.log]]></content>
      <categories>
        <category>工具</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[JVM分析工具、方法]]></title>
    <url>%2F2018%2F11%2F25%2FJVM%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7%E3%80%81%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[命令JDK内置工具使用 - 冯立彬的博客 - CSDN博客 工具 Eclipse Memory Analyzer （MAT） An internal error occurred during: “Parsing heap dump from XXX”错误~/tools/JVM Analyze/mat.app/Contents/Eclipse/MemoryAnalyzer.ini MemoryAnalyzer.ini中的参数一般默认为-vmargs– Xmx1024m，这就够用了。假如你机器的内存不大，改大该参数的值，会导致MemoryAnalyzer启动时，报错:Failed to create the Java Virtual Machine. 当你导出的dump文件的大小大于你配置的1024m（说明1中，提到的配置：-vmargs– Xmx1024m），MAT输出分析报告的时候，会报错：An internal error occurred during: “Parsing heap dump from XXX”。适当调大说明1中的参数即可。 jprofiler IBM® HeapAnalyzer Censum Gcviewer Universal JVM GC analyzer - Java Garbage collection log analysis made easy 用这些工具分析head dump文件，看看分析的结果。 用gcLogViewer分析gc.log，记录下FullGC的几个点，再到gc.log中具体去看那段时间的gc情况，一般就可以分析出FullGC的原因。 使用jstack和TDA进行java线程dump分析 - everlasting_188-java从业者 - CSDN博客通过jinfo工具在full GC前后做heap dump - Script Ahead, Code Behind - ITeye博客 JVM Thread dump analyzer - 在线Java线程分析 几个比较实用的JVM进程分析命令常用命令 查看进程JVM参数jcmd pid VM.flagsjinfo -flags pid （结果比上面的命令较全一些） 提前设置FullGCjinfo -flag +HeapDumpBeforeFullGC pidjinfo -flag +HeapDumpAfterFullGC pidjinfo -flag HeapDumpPath=/home/app pid 立即dump #将pid对应的jvm进程堆内存dump到filename文件jmap -dump:[live,]format=b,file= #显示堆中对象的统计信息，如类、实例数量等jmap -histo jmap -permstat #以classloader为统计口径显示永久代内存状态，only for linuxjmap -histo:live pid （会立即触发Full GC）jmap -dump:file=文件名.dump pidjmap -dump:format=b,file=d:/test.hprof pid 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455jmap -heap pid1. -XX:+HeapDumpOnOutOfMemoryError当OutOfMemoryError发生时自动生成 Heap Dump 文件。2. -XX:+HeapDumpBeforeFullGC当 JVM 执行 FullGC 前执行 dump。3. -XX:+HeapDumpAfterFullGC当 JVM 执行 FullGC 后执行 dump。4. -XX:+HeapDumpOnCtrlBreak交互式获取dump。在控制台按下快捷键Ctrl + Break时，JVM就会转存一下堆快照。5. -XX:HeapDumpPath=d:\test.hprof指定 dump 文件存储路径。注意：JVM 生成 Heap Dump 的时候，虚拟机是暂停一切服务的。如果是线上系统执行 Heap Dump 时需要注意。jps：显示本机所有jvm进程jps -q #只显示进程号jps -l #显示主类全名或所在jar路径jps -m #显示传给main类的参数信息jps -v #显示进程启动时指定的jvm参数jinfo：查看或设置java虚拟机参数jinfo -flag MaxPermSize &lt;pid&gt; #显示该jvm进程的-XX:MaxPermSize参数值（无所谓是否在启动脚本中设置了该参数）jstat：虚拟机统计信息监视，可以监控类装载、内存gc情况、jit编译情况等jstat -class &lt;pid&gt; #监视类装载情况jstat -gc|gcdetail|gcutil|gccause &lt;pid&gt; #gc情况与内存使用jstat -gcnew|gcnewcapacity &lt;pid&gt; #新生代gc情况jstat -gcold|gcoldcapacity &lt;pid&gt; #老年代gc情况jstat -gcpermdetail &lt;pid&gt; #持久带gc情况jstat -gc &lt;pid&gt; 100ms 4 #每隔100ms检测gc情况，一共检测4次(信息比下面这个命令详细)jstat -gcutil 193 1000 //信息是占比#每隔1000ms检测gc情况jstat -gc protocal://&lt;pid&gt;@hostname:port/servername #检测远程主机jmap：java内存映射工具，可查看堆内存信息jmap -dump:[live,]format=b,file=&lt;filename&gt; &lt;pid&gt; #将pid对应的jvm进程堆内存dump到filename文件jmap -histo &lt;pid&gt; #显示堆中对象的统计信息，如类、实例数量等jmap -permstat &lt;pid&gt; #以classloader为统计口径显示永久代内存状态，only for linuxjmap -histo:live pid （会立即触发Full GC）jmap -dump:file=文件名.dump pidjmap -dump:format=b,file=d:/test.hprof pidjhat：虚拟机堆dump文件查看分析工具，执行后会启动一个http服务器，用网页即可看见堆内对象的情况，亦可以使用OQL查询jhat &lt;pid&gt;jstack：java线程堆栈查看工具jstack -l &lt;pid&gt; #加l参数同时会显示锁信息jconsole：图形化的java进程监控工具提供查看系统CPU，进程内存、线程、对象等信息jvisualvm：图形化的java进程AllInOne处理工具除jconsole功能外，还提供堆dump与分析、动态对象性能分析、离线快照等功能，另外其可以通过plugin插件进行功能扩展]]></content>
      <categories>
        <category>Java</category>
        <category>JVM</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[位运算]]></title>
    <url>%2F2018%2F10%2F30%2F%E4%BD%8D%E8%BF%90%E7%AE%97%2F</url>
    <content type="text"><![CDATA[Bit，Byte，Word，Dword，Qwordbit，通常指一个二进制位，八个比特(Bit)称为一个字节（Byte），两个字节称为一个字（Word），两个字称为一个双字（Dword），两个双字称为一个四字（Qword）。 类型范围最大负数：10000000 00000000 00000000 00000000最大正数：01111111 11111111 11111111 11111111 原码 反码 补码原码： 将一个数字转换成二进制就是这个数值的原码。12int a = 5; //原码 0000 0000 0000 0101int b = -3; //原码 1000 0000 0000 0011 反码：分两种情况：正数和负数 正数：正数的反码就是原码。 负数：负数的反码是在原码的基础上，符号位不变 其它位都取反。12345 的原码：0000 0000 0000 01015 的反码：0000 0000 0000 0101-3 的原码：1000 0000 0000 0011-3 的反码：1111 1111 1111 1100 补码:仍然分正数和负数两种情况 正数： 正数的补码就是原码。 负数： 负数的补码在反码的基础上加1。123455 的反码：0000 0000 0000 01015 的补码：0000 0000 0000 0101-3 的反码：1111 1111 1111 1100-3 的补码: 1111 1111 1111 1101 其实负数的：十进制变二进制：原码–反码–加一（补码）；二进制变十进制：减一–反码–原码。 位运算符&amp; 与运算符规则： 从高到低，两个数的对应bit位相与，两个位都为 1 时，结果才为 1，否则为0。123456783的二进制：0000 0011&amp;5的二进制：0000 0101=0000 0001所以3 &amp; 5 = 1PS : 因为是整数高位为0，所以均省略。 | 或运算符规则： 从高到低，两个数的对应bit位相或，两个位都是 0 时，结果才为 0，否则为1。12345673的二进制：0000 0011|5的二进制：0000 0101=0000 0111所以3 | 5 = 7 ~ 取反运算符规则： 从高到低，0 变 1，1 变 0。123456783的二进制：0000 0011~3 的二进制：1111111 11111111 11111111 111111100所以~3 = -4-5的二进制：0000 0101~-5的二进制：00000000 00000000 00000000 00000100所以~-5 = 4 ^ 异或运算符规则： 从高到低，两个数的对应bit位相异或，两个位相同时为 0，相异为 1，相同为0。1234567893的二进制：0000 0011^5的二进制：0000 0101=0000 0110所以3 ^ 5 = 6值得注意的是 3 ^ 5 = 6,而 6 ^ 5 = 3所以交换两个变量可以用异或。 &gt;&gt; 右移运算符规则： a &gt;&gt; b 将数值 a 的二进制数值从 0 位算起到第 b - 1 位，整体向右方向移动 b 位，符号位不变，高位空出来的位补数值 0。 正数： 12345616的二进制：0001 000016 &gt;&gt; 2=0000 0100所以16 &gt;&gt; 2 = 4 负数： 123456-16的二进制：11111111 11111111 11111111 11110000-16 &gt;&gt; 2=11111111 11111111 11111111 11111100所以-16 &gt;&gt; 2 = -4 &lt;&lt; 左移运算符规则： a &lt;&lt; b 将数值 a 的二进制数值从 0 位算起到第 b - 1 位，整体向左方向移动 b 位，符号位不变，低位空出来的位补数值 0。 正数： 1234561的二进制：0000 00011 &lt;&lt; 3=0001000所以1 &lt;&lt; 3 = 8 = 1 * 2的3次幂 负数： 123456-2的二进制：11111111 11111111 11111111 11111110-2 &lt;&lt; 3=11111111 11111111 11111111 11110000所以-2 &lt;&lt; 3 = -8 &gt;&gt;&gt; 无符号右移运算符规则： 与右移不同的是，负数右移时，高位补0。 正数：和普通右移无区别。 负数：123456-2的二进制：11111111 11111111 11111111 11111110-2 &gt;&gt;&gt; 3=00011111 11111111 11111111 11111111所以-2 &gt;&gt;&gt; 3 = 536870911 移位操作说明 正数左移N位表示乘以2的N次幂，右移N位表示除以2的N次幂； 负数移位最高位符号位不变，规则同上。 整型最大值向左移位会越位到负值，因为低位补0了 整型最小值左移会变成0，因为原来是最高位是1，其余是0，左移则全为0 12345678910int x = Integer.MAX_VALUE &lt;&lt; 1;// int x = Integer.MIN_VALUE &lt;&lt; 1;// 整型的二进制字符串String y = Integer.toBinaryString(x);// 将二进制字符串用大整数类型存储，基本类型范围不够容纳BigInteger z = new BigInteger(y);System.out.println("十进制：" + x);System.out.println("二进制字符串：" +y);System.out.println("二进制大整数：" +z);System.out.println("二进制大整数补齐32位：" + String.format("%032d", z));]]></content>
      <categories>
        <category>位运算</category>
      </categories>
      <tags>
        <tag>位运算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown使用]]></title>
    <url>%2F2018%2F10%2F20%2FMarkdown%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[目录 入门手册 空格&amp;换行 超链接 图床 入门手册Learning-Markdown (Markdown 入门参考) 空格 使用 nbsp 标签 &amp; n b s p ; 空格（去掉空格） 换行 使用br标签 &lt; / b r &gt;回车（去掉空格)我这里是将/br标签分开写的，以免生效回车换行看到效果，看不到代码。 在末尾敲击两个以上空白，然后回车 首行缩进 使用特殊占位符 不同占位符所占空白是不一样大的。 123【1】 &amp;ensp;或&amp;#8194; //半角【2】 &amp;emsp;或&amp;#8195; //全角【3】 &amp;nbsp;或&amp;#160; 三.超链接Markdown支持两种形式的链接语法：行内式和参考式，行内式一般用的比较多。3.1.行内式语法：12[打开百度](http://www.baidu.com)[打开百度](http://www.baidu.com &quot;百度&quot;) 说明: []里写链接文字，()里写链接地址, ()中的“”中可以为链接指定title属性，title属性可加可不加。==title属性的效果是鼠标悬停在链接上会出现指定的 title文字。链接文字这样的形式。链接地址与链接标题前有一个空格。== 展示效果:打开百度打开百度 汉字 第二行#### 3.2.参考式:参考式超链接一般用在学术论文上面，或者另一种情况，如果某一个链接在文章中多处使用，那么使用引用 的方式创建链接将非常好，它可以让你对链接进行统一的管理。#### 语法:12345678我经常浏览的几个网站[Google][1]、[Baidu][2]、[51CTO][3]和看视频的网站[爱奇艺][4]感觉都是很不错的[网站][].[1]:http://www.google.com &quot;google&quot;[2]:http://www.baidu.com &quot;Baidu&quot;[3]:http://www.51cto.com &quot;51cto&quot;[4]:http://www.aiqiyi.com &quot;aiqiyi&quot;[网站]:http://www.qq.com#### 展示效果： 我经常浏览的几个网站Google、Baidu、51CTO和看视频的网站爱奇艺感觉都是很不错的网站. 有道云的Markdown上传图片问题 答主自己平时用谷歌浏览器，装了新浪图床的插件，然后需要在md插入图片和时候，就直接拖动或复制图片到新浪图床，自动生成链接。 免费的图片分享链接 – 有道云笔记 联想到Markdown的图床 Markdown 配置七牛云作为图床 如何使用七牛云做为图床？]]></content>
      <categories>
        <category>markdown</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[如何在默认安装openjdk的Linux系统中安装独立JDK]]></title>
    <url>%2F2017%2F07%2F10%2Fjava-2017-07-10-%E5%A6%82%E4%BD%95%E5%9C%A8%E9%BB%98%E8%AE%A4%E5%AE%89%E8%A3%85openjdk%E7%9A%84Linux%E7%B3%BB%E7%BB%9F%E4%B8%AD%E5%AE%89%E8%A3%85%E7%8B%AC%E7%AB%8BJDK%2F</url>
    <content type="text"><![CDATA[今天总结一下在Linux系统中卸载默认的openjdk改为我们自己独立安装的oracle的Jdk版本。就像我们在Windows上安装的环境一样。 1.卸载&amp;下载 2.解压安装 3.修改配置 4.选择使用JAVA的版本 5.测试 一、卸载&amp;下载 1、卸载自带的opendjkrpm –qa|grep jdk rpm –e –nodeps jdk*** //将过滤出的结果进行卸载 2、下载一个Sun的JDK（现在应该叫oracle的JDK）下一个自解压的tar包。这里我下载的是jdk-7u79-linux-x64.tar.gz 下载地址 : 点击这里 二、解压安装 1.解压jdk-7u79-linux-x64.tar.gz 2.将解压后jdk-7u79-linux-x64.tar.gz复制到/usr/java下 三、修改配置 方法1：修改/etc/profile 文件所有用户的 shell都有权使用这些环境变量 在 shell终端执行命令：vi /etc/profile 在 profile文件末尾加入： JAVA_HOME=/usr/jdk1.7.0_79 JRE_HOME=/usr/local/java/jdk1.7.0_79/jre PATH=$JAVA_HOME/bin:$PATH CLASSPATH=.:$JAVA_HOME/lib/dt.jar: $JAVA_HOME/lib/tools.jar export JAVA_HOME,JRE_HOME,PATH,CLASSPATH PS：上面我们说的修改配置系统环境变量是在Unix操作系统下面的。下面来说说在DOS系统下面如何更改配置系统环境变量。 DOS: 在系统变量里新建JAVA_HOME变量，变量值为：D:\others\JAVA\JDK（根据自己的安装路径填写） 新建Classpath变量，在Classpath变量（已存在不用新建）添加变量值，变量值为：.;%JAVA\_HOME%\lib;%JAVA_HOME%\lib\tools.jar; 在path变量（已存在不用新建）添加变量值：%JAVA\_HOME%\bin;%JAVA_HOME%\jre\bin（注意变量值之间用“;”隔开）eg:;%JAVA\_HOME%\lib;%JAVA\_HOME%\lib\tools.jar;%JAVA\_HOME%\bin;%JAVA\_HOME%\jre\bin; 测试是否配置成功在dos中，输入命令java，回车后应该会出现java的各种命令；javac 出现相关编译的命令；java -version 出现jdk版本号补充环境变量的解析:JAVA_HOME:jdk的安装路径Classpath:java加载类路径，只有类在classpath中java命令才能识别，在路径前加了个”.”表示当前路径。path：系统在任何路径下都可以识别java,javac命令。 重启系统ps: 如果你不想重新系统，可以用命令source /etc/profile使配置文件立即生效。否则只能重启系统才能使配置参数生效。然后我们可以通过 echo $JAVA_HOME echo $PATH echo $CLASSPATH 查看配置的信息。但是我最后还是重启了才真正生效。 方法2：修改.bashrc文件如果你需要给某个用户权限使用这些环境变量，你只需要修改其个人用户主目录下的.bashrc就可以了,而不像第一种方法给所有用户权限。在 shell终端执行命令：vi ~/.bashrc在.bashrc文件末尾加入： set JAVA_HOME=/usr/jdk1.7.0_79 export JAVA_HOME set PATH=$JAVA_HOME/bin:$PATH export PATH set CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar export CLASSPATH 重新登录注意：Linux使用:(冒号)而不是;(分号)来分隔路径 四、选择使用JAVA的版本 更新参数使配置生效 update-alternatives --install /usr/bin/java java /usr/jdk1.7.0\_79/bin/java 300 update-alternatives --install /usr/bin/javac javac /usr/jdk1.7.0\_79/bin/javac 300 选择需要使用的版本在终端输入命令：update-alternatives –config java 五、测试 进行完如上配置后，就可以进行测试了在DOS或终端下输入 java -version，然后输出显示，显示出来的是当前系统JRE的最高版本我这里显示的是： ps：环境变量配置文件在Ubuntu中有如下几个文件可以设置环境变量 /etc/profile:在登录时,操作系统定制用户环境时使用的第一个文件,此文件为系统的每个用户设置环境信息,当用户第一次登录时,该文件被执行。 /etc/environment:在登录时操作系统使用的第二个文件,系统在读取你自己的profile前,设置环境文件的环境变量。 ~/.bash_profile:在登录时用到的第三个文件是.profile文件,每个用户都可使用该文件输入专用于自己使用的shell信息,当用户登录时,该文件仅仅执行一次!默认情况下,他设置一些环境变量,执行用户的.bashrc文件。/etc/bashrc:为每一个运行bash shell的用户执行此文件.当bash shell被打开时,该文件被读取. ~/.bashrc:该文件包含专用于你的bash shell的bash信息,当登录时以及每次打开新的shell时,该该文件被读取。几个环境变量的优先级1&gt;2&gt;3]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Jdk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用Hexo + GitHub搭建免费的个人博客]]></title>
    <url>%2F2017%2F07%2F03%2Fhexo-2017-07-03-%E5%88%A9%E7%94%A8Hexo-GitHub%E6%90%AD%E5%BB%BA%E5%85%8D%E8%B4%B9%E7%9A%84%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[今天给大家带来一份用Hexo + Github 搭建属于自己的个人博客的教程。其实现在这种博客的搭建方式有很多种。最早我见的是Jekyll、接下来这个Hexo，最近在研究Python发现用Flask和Django都可以搭建的，只是路数不同罢了。我选择了这个Hexo，目前这个用的人也比较多，应该说是简单易搭建吧，可扩展也可自己美化。话不多说，下面就开始。 1.环境配置 2.Hexo安装部署 3.错误总结 1.环境配置首先要明确有几个环境是必须有的。没有的话请先安装。 Git（官网下载较慢，我建议用这个网址gitb,org） 作用：用来提交Hexo的内容。 nodejs（我建议用v4.*版本较好，官网有6.*和8.*的我装上后有点问题） 作用：用来生成静态页面的。 Github的账号（自己申请，并创建一个名为yourname.github.io的仓库） 自行安装完环境后，将自己 SSH key导入到申请的GitHub中。建议导入，不然后面每次提交代码都要手动输入GitHub的账号密码，相当麻烦。 2.Hexo安装部署Hexo的安装也相当简单，以Windows为例： $ cd d:/hexo $ npm install hexo-cli -g # -g代表全局安装 $ hexo init blog # 初始化blog目录 $ cd blog $ npm install # 安装依赖的组件 $ hexo g # 或者hexo generate $ hexo s # 或者hexo server，可以在http://localhost:4000/ 查看 说几个比较常用的命令: 1. hexo generate (hexo g) 生成静态文件，会在当前目录下生成一个新的叫做public的文件夹 2. hexo server (hexo s) 启动本地web服务，用于博客的本地预览 3. hexo deploy (hexo d) 发布博客到远端 4. hexo clena 清除hexo g生成的本地缓存 5. hexo new "postName" #新建文章 6. hexo new page "pageName" #新建页面 还有一些常用的组合 hexo d -g #生成后+远程部署 hexo s -g #生成后+本地预览 现在我们来看一下本地预览的效果吧 `hexo g` `hexo s` 其实这里有个问题，默认的4000端口我在Windows上一直打不开，我没有在配置文件中重新设置，所以我每次启动的时候都会用这个命令指定端口`hexo s -p 40000` 我直接加了个0，用了40000端口。 出现下面这个就说明你可以开始用网页在本地预览了。 INFO Start processing INFO Hexo is running at http://localhost:40000/. Press Ctrl+C to stop. 预览图如下： ![预览效果](/images/20170703161639.png) 然后你就可以发布到你的Github上了 用命令`hexo d` 即可。但是我们发现需要输入Github的账号密码，所以这里还需要配置你的Github的地址， 编辑本地的`_config.yml` 文件，这是关于Hexo的配置文件。找到如下配置项： deploy: type: git repository: git@github.com:Lancelothe/Lancelothe.github.io.git branch: master 按照我的格式填写即可，我的Github名字是Lancelothe，所以你需要将这个改为你的名字。关于type和repository的格式似乎在Hexo3.0版本以上就是需要这样写，以前好像type可以写成github.如何查看你的Hexo版本呢？ 用hexo -v命令 hexo: 3.3.7 hexo-cli: 1.0.3 os: Windows_NT 6.1.7601 win32 x64 http_parser: 2.5.2 node: 4.4.2 v8: 4.5.103.35 uv: 1.8.0 zlib: 1.2.8 ares: 1.10.1-DEV icu: 56.1 modules: 46 openssl: 1.0.2g 到此为止，你的Hexo个人博客就已经搭建完毕了。下面来看看搭建过程中哪些可能遇到的问题 3.错误总结 问题1：npm install 报 command not found原因：PATH配置不对。解决：选择『计算机』-『属性』-『高级系统设置』-『环境变量』，先查看了『系统变量』部分，发现安装后确实在系统变量的Path后追加了安装路径，即：C:\Program Files\nodejs；然后，打开『用户环境变量』部分查看了下Path的值，发现在最后系统自动加入了C:\Users\s94983\AppData\Roaming\npm，在『用户环境变量』部分的Path下再追加C:\Program Files\nodejs，然后关闭掉git base，（有可能需要重启电脑才可生效）问题解决！ 问题2：hexo deploy时重复输入用户名密码的问题原因：repository配置时没有采用git@github.com的形式，而是采用了老的https://github.com解决：采用git@github.com形式即可。 问题3：ERROR Deployer not found: git 或者 ERROR Deployer not found: github原因：未安装依赖包解决：使用 npm install hexo-deployer-git --save 安装依赖 问题4：npm安装时下载速度慢解决： 可以换成淘宝的镜像源。镜像举例：1.临时使用npm --registry https://registry.npm.taobao.org install express 2.持久使用12345npm config set registry https://registry.npm.taobao.org`//配置后可通过下面方式来验证是否成功npm config get registry或npm info express 3.通过cnpm 使用12npm install -g cnpm --registry=https://registry.npm.taobao.org使用cnpm install expresstall express 后面还会为大家带来Hexo的高级用法的，谢谢支持。]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>博客</tag>
      </tags>
  </entry>
</search>
